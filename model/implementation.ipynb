{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ------------------ Base Building Blocks ------------------\n",
    "class ConvBNSiLU(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=1, s=1, p=None):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = k // 2\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = c1 == c2\n",
    "        if self.use_shortcut:\n",
    "            self.conv = ConvBNSiLU(c1, c2, k=1)\n",
    "        else:\n",
    "            self.conv1 = ConvBNSiLU(c1, c2, k=1)\n",
    "            self.conv2 = ConvBNSiLU(c2, c2, k=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_shortcut:\n",
    "            return self.conv(x)\n",
    "        else:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            return torch.cat([x, x2], dim=1)\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_ch, reduction=16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_ch, in_ch // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch // reduction, in_ch, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class C3Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, n=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNSiLU(in_ch, in_ch, k=1)\n",
    "        self.bottlenecks = nn.Sequential(*[Bottleneck(in_ch, in_ch) for _ in range(n)])\n",
    "        self.concat_conv = ConvBNSiLU(in_ch * 2, out_ch, k=1)\n",
    "        self.se = SEBlock(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.conv1(x)\n",
    "        y2 = self.bottlenecks(y1)\n",
    "        cat = torch.cat((y1, y2), dim=1)\n",
    "        out = self.concat_conv(cat)\n",
    "        return self.se(out)\n",
    "\n",
    "# ------------------ YOLOv5m Architecture (Kidney Stone Detection) ------------------\n",
    "class YOLOv5mSE(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Reduced channel dimensions\n",
    "        self.stem = ConvBNSiLU(3, 24, k=3, s=1)  # Reduced from 32\n",
    "        self.stage1 = C3Block(24, 48, n=1)       # Reduced from 64\n",
    "        self.stage2 = C3Block(48, 96, n=2)       # Reduced from 128, n=2 instead of 3\n",
    "        self.stage3 = C3Block(96, 192, n=2)      # Reduced from 256, n=2 instead of 3\n",
    "        self.stage4 = C3Block(192, 384, n=1)     # Reduced from 512\n",
    "\n",
    "        # Neck with reduced channels\n",
    "        self.neck1 = ConvBNSiLU(384, 192, k=1)   # Reduced from 256\n",
    "        self.neck2 = C3Block(192 + 192, 192, n=1)  # Reduced from 256\n",
    "\n",
    "        self.neck3 = ConvBNSiLU(192, 96, k=1)    # Reduced from 128\n",
    "        self.neck4 = C3Block(96 + 96, 96, n=1)   # Reduced from 128\n",
    "\n",
    "        # Head with reduced channels\n",
    "        self.detect1 = nn.Conv2d(96, (num_classes + 5) * 3, 1)   # Reduced from 128\n",
    "        self.detect2 = nn.Conv2d(192, (num_classes + 5) * 3, 1)  # Reduced from 256\n",
    "        self.detect3 = nn.Conv2d(384, (num_classes + 5) * 3, 1)  # Reduced from 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone\n",
    "        x = self.stem(x)\n",
    "        x1 = self.stage1(x)\n",
    "        x2 = self.stage2(x1)\n",
    "        x3 = self.stage3(x2)\n",
    "        x4 = self.stage4(x3)\n",
    "\n",
    "        # Neck with explicit size matching\n",
    "        n1 = self.neck1(x4)\n",
    "        n1_up = nn.functional.interpolate(n1, size=x3.shape[2:], mode='nearest')\n",
    "        n2 = self.neck2(torch.cat([n1_up, x3], dim=1))\n",
    "\n",
    "        n2_up = nn.functional.interpolate(self.neck3(n2), size=x2.shape[2:], mode='nearest')\n",
    "        n3 = self.neck4(torch.cat([n2_up, x2], dim=1))\n",
    "\n",
    "        # Head\n",
    "        out1 = self.detect1(n3)\n",
    "        out2 = self.detect2(n2)\n",
    "        out3 = self.detect3(x4)\n",
    "\n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----- Base Blocks (same as yours, no change needed) -----\n",
    "class ConvBNSiLU(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=1, s=1, p=None):\n",
    "        super().__init__()\n",
    "        if p is None:\n",
    "            p = k // 2\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = c1 == c2\n",
    "        if self.use_shortcut:\n",
    "            self.conv = ConvBNSiLU(c1, c2, k=1)\n",
    "        else:\n",
    "            self.conv1 = ConvBNSiLU(c1, c2, k=1)\n",
    "            self.conv2 = ConvBNSiLU(c2, c2, k=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_shortcut:\n",
    "            return self.conv(x)\n",
    "        else:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            return torch.cat([x, x2], dim=1)\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_ch, reduction=16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_ch, in_ch // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch // reduction, in_ch, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class C3Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, n=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNSiLU(in_ch, in_ch, k=1)\n",
    "        self.bottlenecks = nn.Sequential(*[Bottleneck(in_ch, in_ch) for _ in range(n)])\n",
    "        self.concat_conv = ConvBNSiLU(in_ch * 2, out_ch, k=1)\n",
    "        self.se = SEBlock(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.conv1(x)\n",
    "        y2 = self.bottlenecks(y1)\n",
    "        cat = torch.cat((y1, y2), dim=1)\n",
    "        out = self.concat_conv(cat)\n",
    "        return self.se(out)\n",
    "\n",
    "# ----- YOLOv5nSE Nano Model -----\n",
    "class YOLOv5nSE(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Super lightweight stem and stages\n",
    "        self.stem = ConvBNSiLU(3, 16, k=3, s=1)\n",
    "        self.stage1 = C3Block(16, 32, n=1)\n",
    "        self.stage2 = C3Block(32, 64, n=1)\n",
    "        self.stage3 = C3Block(64, 128, n=1)\n",
    "        self.stage4 = C3Block(128, 256, n=1)\n",
    "\n",
    "        # Neck\n",
    "        self.neck1 = ConvBNSiLU(256, 128, k=1)\n",
    "        self.neck2 = C3Block(128 + 128, 128, n=1)\n",
    "\n",
    "        self.neck3 = ConvBNSiLU(128, 64, k=1)\n",
    "        self.neck4 = C3Block(64 + 64, 64, n=1)\n",
    "\n",
    "        # Detection Head\n",
    "        self.detect1 = nn.Conv2d(64, (num_classes + 5) * 3, 1)\n",
    "        self.detect2 = nn.Conv2d(128, (num_classes + 5) * 3, 1)\n",
    "        self.detect3 = nn.Conv2d(256, (num_classes + 5) * 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone\n",
    "        x = self.stem(x)\n",
    "        x1 = self.stage1(x)\n",
    "        x2 = self.stage2(x1)\n",
    "        x3 = self.stage3(x2)\n",
    "        x4 = self.stage4(x3)\n",
    "\n",
    "        # Neck\n",
    "        n1 = self.neck1(x4)\n",
    "        n1_up = F.interpolate(n1, size=x3.shape[2:], mode='nearest')\n",
    "        n2 = self.neck2(torch.cat([n1_up, x3], dim=1))\n",
    "\n",
    "        n2_up = F.interpolate(self.neck3(n2), size=x2.shape[2:], mode='nearest')\n",
    "        n3 = self.neck4(torch.cat([n2_up, x2], dim=1))\n",
    "\n",
    "        # Head\n",
    "        out1 = self.detect1(n3)\n",
    "        out2 = self.detect2(n2)\n",
    "        out3 = self.detect3(x4)\n",
    "\n",
    "        return out1, out2, out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/1054 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 223\u001b[0m\n\u001b[0;32m    220\u001b[0m criterion \u001b[38;5;241m=\u001b[39m YoloLoss()\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Training with progress bars\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 148\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epochs)\u001b[0m\n\u001b[0;32m    145\u001b[0m imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    146\u001b[0m targets \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[1;32m--> 148\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m    150\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps  \u001b[38;5;66;03m# Normalize loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 103\u001b[0m, in \u001b[0;36mYOLOv5nSE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    101\u001b[0m n1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck1(x4)\n\u001b[0;32m    102\u001b[0m n1_up \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(n1, size\u001b[38;5;241m=\u001b[39mx3\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m n2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneck2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn1_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m n2_up \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck3(n2), size\u001b[38;5;241m=\u001b[39mx2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m n3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck4(torch\u001b[38;5;241m.\u001b[39mcat([n2_up, x2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m, in \u001b[0;36mC3Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     63\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottlenecks(y1)\n\u001b[0;32m     64\u001b[0m cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((y1, y2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mConvBNSiLU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\functional.py:2380\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------- Dataset with Bilateral Filtering + Augmentation --------------------\n",
    "class KidneyStoneDataset(Dataset):\n",
    "    def __init__(self, split_dir, img_size=320):\n",
    "        self.image_dir = os.path.join(split_dir, \"images\")\n",
    "        self.label_dir = os.path.join(split_dir, \"labels\")\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "        self.img_size = img_size\n",
    "        self.transforms = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=10),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace('.png', '.txt').replace('.jpg', '.txt'))\n",
    "\n",
    "        # Read image and apply bilateral filter\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        img_tensor = self.transforms(img)\n",
    "\n",
    "        # Load labels (YOLO format)\n",
    "        targets = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    targets.append([cls, x, y, w, h])\n",
    "\n",
    "        return img_tensor, torch.tensor(targets), img_name\n",
    "\n",
    "\n",
    "# -------------------- Custom YOLO Loss --------------------\n",
    "def bbox_ciou(box1, box2):\n",
    "    # Compute Complete IoU (CIoU)\n",
    "    b1_x1, b1_y1 = box1[..., 0] - box1[..., 2] / 2, box1[..., 1] - box1[..., 3] / 2\n",
    "    b1_x2, b1_y2 = box1[..., 0] + box1[..., 2] / 2, box1[..., 1] + box1[..., 3] / 2\n",
    "    b2_x1, b2_y1 = box2[..., 0] - box2[..., 2] / 2, box2[..., 1] - box2[..., 3] / 2\n",
    "    b2_x2, b2_y2 = box2[..., 0] + box2[..., 2] / 2, box2[..., 1] + box2[..., 3] / 2\n",
    "\n",
    "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1, min=0)\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "    union = b1_area + b2_area - inter_area\n",
    "    iou = inter_area / (union + 1e-6)\n",
    "\n",
    "    # center distance\n",
    "    center_dist = (box1[..., 0] - box2[..., 0]) ** 2 + (box1[..., 1] - box2[..., 1]) ** 2\n",
    "    # diagonal length of the smallest enclosing box\n",
    "    enc_x1 = torch.min(b1_x1, b2_x1)\n",
    "    enc_y1 = torch.min(b1_y1, b2_y1)\n",
    "    enc_x2 = torch.max(b1_x2, b2_x2)\n",
    "    enc_y2 = torch.max(b1_y2, b2_y2)\n",
    "    enc_diag = (enc_x2 - enc_x1) ** 2 + (enc_y2 - enc_y1) ** 2\n",
    "\n",
    "    v = (4 / (np.pi ** 2)) * torch.pow(torch.atan(box1[..., 2] / box1[..., 3]) - torch.atan(box2[..., 2] / box2[..., 3]), 2)\n",
    "    alpha = v / (1 - iou + v + 1e-6)\n",
    "    ciou = iou - center_dist / (enc_diag + 1e-6) - alpha * v\n",
    "    return ciou\n",
    "\n",
    "\n",
    "class YoloLoss(torch.nn.Module):\n",
    "    def __init__(self, lambda_cls=1.0, lambda_obj=1.0, lambda_box=5.0):\n",
    "        super().__init__()\n",
    "        self.lambda_cls = lambda_cls\n",
    "        self.lambda_obj = lambda_obj\n",
    "        self.lambda_box = lambda_box\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # Decode preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = torch.cat([p.view(p.size(0), -1, p.size(-1)) for p in preds], dim=1)\n",
    "\n",
    "        batch_size = preds.size(0)\n",
    "        device = preds.device  # Ensure all tensors are on the same device\n",
    "        loss_cls = torch.tensor(0.0, device=device)\n",
    "        loss_obj = torch.tensor(0.0, device=device)\n",
    "        loss_box = torch.tensor(0.0, device=device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            pred = preds[b]  # [N, 6] or [N, 85] -> assuming [x, y, w, h, obj, cls...]\n",
    "            t = targets[b]   # [M, 5] -> [cls, x, y, w, h]\n",
    "\n",
    "            if len(t) == 0:\n",
    "                continue\n",
    "\n",
    "            for gt in t:\n",
    "                gt_cls, gx, gy, gw, gh = gt.to(pred.device)\n",
    "                gt_box = torch.tensor([gx, gy, gw, gh], device=pred.device)\n",
    "\n",
    "                ious = bbox_ciou(pred[:, :4], gt_box.unsqueeze(0))  # Shape: [N]\n",
    "                best_idx = torch.argmax(ious)\n",
    "\n",
    "                pred_box = pred[best_idx, :4]\n",
    "                pred_obj = pred[best_idx, 4]\n",
    "                pred_cls = pred[best_idx, 5:]\n",
    "\n",
    "                ciou = bbox_ciou(pred_box.unsqueeze(0), gt_box.unsqueeze(0))  # Shape: [1]\n",
    "                loss_box += (1 - ciou)  # No need to unsqueeze, ciou is already [1]\n",
    "                loss_obj += self.bce(pred_obj, torch.tensor(1.0, device=pred.device))\n",
    "                loss_cls += self.bce(pred_cls[int(gt_cls)], torch.tensor(1.0, device=pred.device))\n",
    "\n",
    "        total_loss = self.lambda_box * loss_box + self.lambda_obj * loss_obj + self.lambda_cls * loss_cls\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- Training Function --------------------\n",
    "def train(model, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        # Create progress bar for epochs\n",
    "        epoch_pbar = tqdm(range(len(train_loader)), \n",
    "                         desc=f'Epoch {epoch+1}/{epochs}',\n",
    "                         position=0)\n",
    "        \n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, (imgs, targets, img_names) in enumerate(train_loader):  # Unpack img_names as well\n",
    "            imgs = imgs.cuda()\n",
    "            targets = [t.cuda() for t in targets]\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss = loss / accumulation_steps  # Normalize loss\n",
    "            loss.backward()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            epoch_pbar.set_postfix({\n",
    "                'loss': f'{total_loss/(i+1):.4f}',\n",
    "                'batch': f'{i+1}/{len(train_loader)}'\n",
    "            })\n",
    "            epoch_pbar.update(1)\n",
    "        \n",
    "        epoch_pbar.close()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs} - Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets, _ in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-sized targets\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    img_names = []\n",
    "    \n",
    "    for img, target, img_name in batch:  # Include img_name\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "        img_names.append(img_name)\n",
    "    \n",
    "    # Stack images (they should all be the same size)\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    return images, targets, img_names\n",
    "\n",
    "# -------------------- Main Script --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath('__file__')), '..', 'dataset', 'train')\n",
    "    dataset = KidneyStoneDataset(path)\n",
    "    \n",
    "    # Reduce batch size to save memory\n",
    "    batch_size = 1  # Reduced from 2\n",
    "    accumulation_steps = 8  # Increased from 4 to maintain effective batch size\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Keep this at 0 to prevent memory issues\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    # Enable memory efficient mode\n",
    "    torch.cuda.empty_cache()  # Clear any unused memory\n",
    "    \n",
    "    model = YOLOv5nSE(num_classes=1).cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = YoloLoss()\n",
    "\n",
    "    # Training with progress bars\n",
    "    train(model, train_loader, optimizer, epochs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/1054 [12:11<?, ?it/s]\n",
      "Epoch 1/2:   0%|          | 0/1054 [10:36<?, ?it/s]\n",
      "Epoch 1/2:   0%|          | 0/1054 [09:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 175\u001b[0m\n\u001b[0;32m    165\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    166\u001b[0m     dataset,\n\u001b[0;32m    167\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mcustom_collate_fn\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# ðŸš¨ Replace this with your YOLO model\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLOv5nSE_Tiny\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[0;32m    178\u001b[0m criterion \u001b[38;5;241m=\u001b[39m YoloLoss()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------- Dataset with Bilateral Filtering + Augmentation --------------------\n",
    "class KidneyStoneDataset(Dataset):\n",
    "    def __init__(self, split_dir, img_size=320):\n",
    "        self.image_dir = os.path.join(split_dir, \"images\")\n",
    "        self.label_dir = os.path.join(split_dir, \"labels\")\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "        self.img_size = img_size\n",
    "        self.transforms = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=10),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace('.png', '.txt').replace('.jpg', '.txt'))\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        img_tensor = self.transforms(img)\n",
    "\n",
    "        targets = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    cls, x, y, w, h = map(float, line.strip().split())\n",
    "                    targets.append([cls, x, y, w, h])\n",
    "\n",
    "        return img_tensor, torch.tensor(targets), img_name\n",
    "\n",
    "# -------------------- CIoU + Custom YOLO Loss --------------------\n",
    "def bbox_ciou(box1, box2):\n",
    "    b1_x1, b1_y1 = box1[..., 0] - box1[..., 2] / 2, box1[..., 1] - box1[..., 3] / 2\n",
    "    b1_x2, b1_y2 = box1[..., 0] + box1[..., 2] / 2, box1[..., 1] + box1[..., 3] / 2\n",
    "    b2_x1, b2_y1 = box2[..., 0] - box2[..., 2] / 2, box2[..., 1] - box2[..., 3] / 2\n",
    "    b2_x2, b2_y2 = box2[..., 0] + box2[..., 2] / 2, box2[..., 1] + box2[..., 3] / 2\n",
    "\n",
    "    inter_x1 = torch.max(b1_x1, b2_x1)\n",
    "    inter_y1 = torch.max(b1_y1, b2_y1)\n",
    "    inter_x2 = torch.min(b1_x2, b2_x2)\n",
    "    inter_y2 = torch.min(b1_y2, b2_y2)\n",
    "\n",
    "    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "    union = b1_area + b2_area - inter_area\n",
    "    iou = inter_area / (union + 1e-6)\n",
    "\n",
    "    center_dist = (box1[..., 0] - box2[..., 0]) ** 2 + (box1[..., 1] - box2[..., 1]) ** 2\n",
    "    enc_x1 = torch.min(b1_x1, b2_x1)\n",
    "    enc_y1 = torch.min(b1_y1, b2_y1)\n",
    "    enc_x2 = torch.max(b1_x2, b2_x2)\n",
    "    enc_y2 = torch.max(b1_y2, b2_y2)\n",
    "    enc_diag = (enc_x2 - enc_x1) ** 2 + (enc_y2 - enc_y1) ** 2\n",
    "\n",
    "    v = (4 / (np.pi ** 2)) * torch.pow(torch.atan(box1[..., 2] / box1[..., 3]) - torch.atan(box2[..., 2] / box2[..., 3]), 2)\n",
    "    alpha = v / (1 - iou + v + 1e-6)\n",
    "    ciou = iou - center_dist / (enc_diag + 1e-6) - alpha * v\n",
    "    return ciou\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, lambda_cls=1.0, lambda_obj=1.0, lambda_box=5.0):\n",
    "        super().__init__()\n",
    "        self.lambda_cls = lambda_cls\n",
    "        self.lambda_obj = lambda_obj\n",
    "        self.lambda_box = lambda_box\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = torch.cat([p.view(p.size(0), -1, p.size(-1)) for p in preds], dim=1)\n",
    "\n",
    "        batch_size = preds.size(0)\n",
    "        device = preds.device\n",
    "        loss_cls, loss_obj, loss_box = 0.0, 0.0, 0.0\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            pred = preds[b]\n",
    "            t = targets[b]\n",
    "            if len(t) == 0:\n",
    "                continue\n",
    "            for gt in t:\n",
    "                gt_cls, gx, gy, gw, gh = gt.to(device)\n",
    "                gt_box = torch.tensor([gx, gy, gw, gh], device=device)\n",
    "                ious = bbox_ciou(pred[:, :4], gt_box.unsqueeze(0))\n",
    "                best_idx = torch.argmax(ious)\n",
    "                pred_box = pred[best_idx, :4]\n",
    "                pred_obj = pred[best_idx, 4]\n",
    "                pred_cls = pred[best_idx, 5:]\n",
    "                ciou = bbox_ciou(pred_box.unsqueeze(0), gt_box.unsqueeze(0))\n",
    "                loss_box += (1 - ciou)\n",
    "                loss_obj += self.bce(pred_obj, torch.tensor(1.0, device=device))\n",
    "                loss_cls += self.bce(pred_cls[int(gt_cls)], torch.tensor(1.0, device=device))\n",
    "\n",
    "        total = self.lambda_box * loss_box + self.lambda_obj * loss_obj + self.lambda_cls * loss_cls\n",
    "        return total\n",
    "\n",
    "# -------------------- Collate Function --------------------\n",
    "def custom_collate_fn(batch):\n",
    "    images, targets, img_names = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    return images, list(targets), img_names\n",
    "\n",
    "# -------------------- Training Function --------------------\n",
    "def train(model, train_loader, optimizer, criterion, epochs, device, accumulation_steps):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        epoch_pbar = tqdm(range(len(train_loader)), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        for i, (imgs, targets, _) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            targets = [t.to(device) for t in targets]\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss = loss / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_pbar.set_postfix({\n",
    "                'loss': f'{total_loss / (i + 1):.4f}',\n",
    "                'batch': f'{i+1}/{len(train_loader)}'\n",
    "            })\n",
    "            epoch_pbar.update(1)\n",
    "\n",
    "        epoch_pbar.close()\n",
    "        print(f\"\\nEpoch {epoch+1} finished - Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# -------------------- Main Execution --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath('__file__')), '..', 'dataset', 'train')\n",
    "    \n",
    "    dataset = KidneyStoneDataset(path)\n",
    "    batch_size = 1\n",
    "    accumulation_steps = 8\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    # ðŸš¨ Replace this with your YOLO model\n",
    "    model = YOLOv5nSE_Tiny(num_classes=1).to(device)\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = YoloLoss().to(device)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    train(model, train_loader, optimizer, criterion, epochs=2, device=device, accumulation_steps=accumulation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channel, channel // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        weight = self.fc(x)\n",
    "        return x * weight\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, se=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SEBlock(out_ch) if se else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        return self.se(x)\n",
    "\n",
    "class YOLOv5nSE_Tiny(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_preds=10):  # num_preds = number of boxes per image\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvBlock(3, 16)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.layer2 = ConvBlock(16, 32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.layer3 = ConvBlock(32, 64)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.layer4 = ConvBlock(64, 128)\n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_preds * (5 + num_classes))  # [x, y, w, h, obj, class_scores]\n",
    "        )\n",
    "        self.num_preds = num_preds\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.layer1(x))\n",
    "        x = self.pool2(self.layer2(x))\n",
    "        x = self.pool3(self.layer3(x))\n",
    "        x = self.pool4(self.layer4(x))\n",
    "        x = self.head(x)\n",
    "        return x.view(x.size(0), self.num_preds, 5 + self.num_classes)  # Shape: [B, N, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple SE Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channel, channel // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        weight = self.fc(x)\n",
    "        return x * weight\n",
    "\n",
    "# Conv + BN + ReLU + SE (Optional)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, se=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 3, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SEBlock(out_ch) if se else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        return self.se(x)\n",
    "\n",
    "# Tiny YOLO-like model\n",
    "class YOLOv5nSE_Tiny(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvBlock(3, 16)      # 224 -> 224\n",
    "        self.pool1 = nn.MaxPool2d(2)        # 224 -> 112\n",
    "\n",
    "        self.layer2 = ConvBlock(16, 32)\n",
    "        self.pool2 = nn.MaxPool2d(2)        # 112 -> 56\n",
    "\n",
    "        self.layer3 = ConvBlock(32, 64)\n",
    "        self.pool3 = nn.MaxPool2d(2)        # 56 -> 28\n",
    "\n",
    "        self.layer4 = ConvBlock(64, 128)\n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))  # -> [B, 128, 1, 1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Sigmoid()  # For binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.layer1(x))\n",
    "        x = self.pool2(self.layer2(x))\n",
    "        x = self.pool3(self.layer3(x))\n",
    "        x = self.pool4(self.layer4(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class KidneyStoneClassificationDataset(Dataset):\n",
    "    def __init__(self, data_dir, img_size=224):\n",
    "        self.image_dir = os.path.join(data_dir, \"images\")\n",
    "        self.label_dir = os.path.join(data_dir, \"labels\")\n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        self.transforms = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomRotation(10),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, img_name.replace('.png', '.txt').replace('.jpg', '.txt'))\n",
    "\n",
    "        img = Image.open(img_path).convert('L')  # grayscale\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = int(f.readline().strip())\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class KidneyStoneCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KidneyStoneCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # for BCEWithLogitsLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Yaswanth Reddy\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "WARNING Dataset 'coco.yaml' images not found, missing path 'C:\\Users\\datasets\\coco\\val2017.txt'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'coco.yaml' error  [WinError 5] Access is denied: 'C:\\\\Users\\\\datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:603\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    602\u001b[0m }:\n\u001b[1;32m--> 603\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\data\\utils.py:472\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# python script\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m<string>:10\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\downloads.py:509\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, dir, unzip, delete, curl, threads, retry, exist_ok)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mdir\u001b[39m)\n\u001b[1;32m--> 509\u001b[0m \u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# make directory\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threads \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'C:\\\\Users\\\\datasets'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 82\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 4. Training Loop\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸŒ€ Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    789\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:153\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:607\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error âŒ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls:\n\u001b[0;32m    609\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding class names with single class.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'coco.yaml' error  [WinError 5] Access is denied: 'C:\\\\Users\\\\datasets'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "def train_model(model):\n",
    "    # 1. Config\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    batch_size = 16\n",
    "    epochs = 15\n",
    "    learning_rate = 1e-3\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath('__file__')), '..', 'dataset')\n",
    "    train_path = os.path.join(path, 'train')\n",
    "    valid_path = os.path.join(path, 'valid')\n",
    "    # 2. Data Loading\n",
    "    train_dataset = KidneyStoneClassificationDataset(train_path)\n",
    "    val_dataset = KidneyStoneClassificationDataset(valid_path)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 3. Model Setup\n",
    "    model = model\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 4. Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f\"\\nðŸŒ€ Epoch {epoch+1}/{epochs}\")\n",
    "        for imgs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"âœ… Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation after each epoch\n",
    "        validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), \"kidney_stone_cnn.pth\")\n",
    "    print(\"\\nðŸ“¦ Model saved as 'kidney_stone_cnn.pth'\")\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    print(f\"ðŸ“Š Validation Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.146-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\python312\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\python312\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\python312\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\python312\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\python312\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\yaswanth reddy\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\yaswanth reddy\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\python312\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\python312\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\python312\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yaswanth reddy\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (80.7.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yaswanth reddy\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Using cached ultralytics-8.3.146-py3-none-any.whl (1.0 MB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "\n",
      "   ---------------------------------------- 0/2 [ultralytics-thop]\n",
      "   ---------------------------------------- 0/2 [ultralytics-thop]\n",
      "   ---------------------------------------- 0/2 [ultralytics-thop]\n",
      "   ---------------------------------------- 0/2 [ultralytics-thop]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   -------------------- ------------------- 1/2 [ultralytics]\n",
      "   ---------------------------------------- 2/2 [ultralytics]\n",
      "\n",
      "Successfully installed ultralytics-8.3.146 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~%p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\Yaswanth Reddy\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "PRO TIP  Replace 'model=yolov5n.pt' with new 'model=yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5nu.pt to 'yolov5nu.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.31M/5.31M [00:03<00:00, 1.56MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5n summary: 153 layers, 2,654,816 parameters, 0 gradients, 7.8 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153, 2654816, 0, 7.840102399999999)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLOv5n model\n",
    "model = YOLO(\"yolov5n.pt\")\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "# Train the model on the COCO8 example dataset for 100 epochs\n",
    "#results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# Run inference with the YOLOv5n model on the 'bus.jpg' image\n",
    "#results = model(\"path/to/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kidney.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-classifier3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=kidney-stone-yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=kidney-stone-yolo\\yolov8n-classifier3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Yaswanth Reddy\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 1.42MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,508,659 parameters, 2,508,643 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:08<00:00, 653kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 1.20.3 MB/s, size: 15.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\train\\labels... 1054 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1054/1054 [00:02<00:00, 367.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 0.60.3 MB/s, size: 17.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\labels... 123 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:00<00:00, 400.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\labels.cache\n",
      "Plotting labels to kidney-stone-yolo\\yolov8n-classifier3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mkidney-stone-yolo\\yolov8n-classifier3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.322G       2.54      3.241      1.169         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:23<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.846      0.169      0.338      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.324G      2.441      1.813      1.103         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:17<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.534      0.425      0.389      0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.324G      2.447      1.477      1.098         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.521      0.446      0.386      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30     0.324G      2.318      1.344      1.083         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.559      0.228      0.218     0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.324G      2.317      1.274      1.062         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:17<00:00,  7.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.671      0.484      0.457       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.324G      2.323      1.188      1.066         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.583      0.406      0.369      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.324G      2.286      1.147      1.053         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.594      0.505      0.453      0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.324G       2.26       1.16      1.062         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:14<00:00,  9.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.623      0.452      0.461      0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.344G      2.224       1.08      1.043         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.661      0.483      0.473      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.344G      2.221      1.092      1.039          8        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.595      0.469      0.447      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.344G      2.202      1.131      1.056         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.687      0.517      0.548      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.344G      2.128      1.057      1.034         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.699      0.538      0.548      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.344G      2.182      1.053      1.025         36        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.647      0.519      0.513      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.344G      2.106      1.012      1.022         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.67      0.532       0.53      0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.344G      2.127      1.036      1.033         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.75      0.527      0.562      0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.344G      2.118      1.021      1.029         45        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:14<00:00,  9.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.645      0.565      0.557      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.344G      2.112      1.024      1.012         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.676      0.507      0.511      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.344G      2.041     0.9659      1.006         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:14<00:00,  9.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.671      0.437      0.454      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.344G      2.041     0.9681      1.015         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:14<00:00,  9.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.714      0.578      0.585      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.344G      2.039     0.9423     0.9988         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.728      0.536      0.563      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.344G      1.958     0.9054      1.001         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.655      0.529       0.51      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.344G       1.99     0.9162      1.007          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.728       0.56      0.582      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.344G      1.983     0.9175       1.01         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.684      0.529      0.532      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.344G      1.979     0.9065      1.004         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.726      0.557      0.569      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.344G      1.939     0.9071      1.004          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:14<00:00,  9.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.695       0.54      0.542      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.344G      1.947     0.8811      0.987          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.706      0.542      0.553      0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.344G       1.91     0.8889     0.9866         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325        0.7       0.56       0.55      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.344G      1.941      0.892     0.9812          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.712      0.554      0.541      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.344G      1.925     0.8603     0.9742          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:13<00:00,  9.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.748      0.584      0.605      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.344G      1.867     0.8408     0.9861          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:21<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.733      0.566      0.586      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.145 hours.\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8n-classifier3\\weights\\last.pt, 5.2MB\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8n-classifier3\\weights\\best.pt, 5.2MB\n",
      "\n",
      "Validating kidney-stone-yolo\\yolov8n-classifier3\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,139 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.748      0.585      0.605      0.237\n",
      "Speed: 0.5ms preprocess, 6.7ms inference, 0.0ms loss, 8.6ms postprocess per image\n",
      "Results saved to \u001b[1mkidney-stone-yolo\\yolov8n-classifier3\u001b[0m\n",
      "ðŸŽ‰ Training complete! Weights saved in 'runs/detect/yolov8n-classifier'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def train_yolo(model):\n",
    "    model = model or YOLO(\"yolov8n.pt\")  # Load YOLOv8n model if not provided\n",
    "\n",
    "    model.train(\n",
    "        data='kidney.yaml',\n",
    "        epochs=30,\n",
    "        imgsz=320,\n",
    "        batch=8,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "        project='kidney-stone-yolo',\n",
    "        name='yolov8n-classifier',\n",
    "        pretrained=True\n",
    "    )\n",
    "\n",
    "    print(\"ðŸŽ‰ Training complete! Weights saved in 'runs/detect/yolov8n-classifier'\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_yolo(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\images\\1-3-46-670589-33-1-63705534438072088700001-5205898188246698645_png_jpg.rf.75a856d4d26f9f0323b495186912084d.jpg: 288x320 7 kidney_stones, 67.9ms\n",
      "Speed: 2.6ms preprocess, 67.9ms inference, 4.5ms postprocess per image at shape (1, 3, 288, 320)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\model\\kidney-stone-yolo\\yolov8s-classifier2\\weights\\best.pt')\n",
    "\n",
    "# Path to input image\n",
    "image_path = r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\images\\1-3-46-670589-33-1-63705534438072088700001-5205898188246698645_png_jpg.rf.75a856d4d26f9f0323b495186912084d.jpg'  # ðŸ” Change this to your image\n",
    "\n",
    "# Run inference\n",
    "results = model(image_path)\n",
    "\n",
    "# Parse results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object\n",
    "    img = result.orig_img.copy()\n",
    "\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box\n",
    "        conf = box.conf[0].item()               # Confidence\n",
    "        label = result.names[int(box.cls[0])]   # Class name\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Show image\n",
    "    cv2.imshow(\"Detected Stones\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save output\n",
    "    cv2.imwrite(\"output_with_stones.png\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63703718086120120200001-5487554579919763006_png_jpg.rf.9fd67251e99a47dbe83a5db6efe6c016.jpg: 288x320 2 kidney_stones, 20.9ms\n",
      "Speed: 2.7ms preprocess, 20.9ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705534438365105500001-5275982036206127404_png_jpg.rf.365c4daf2b772012fe47e07b9daec86e.jpg: 288x320 1 kidney_stone, 19.4ms\n",
      "Speed: 2.5ms preprocess, 19.4ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705540012666937300001-5673688970564737961_png_jpg.rf.15cca2fecc5f56865de3eb405476b90d.jpg: 288x320 1 kidney_stone, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705542123217653900001-5305208767418446842_png_jpg.rf.d6f32a0ac819e4f2a870edfc1ce8079b.jpg: 288x320 2 kidney_stones, 19.8ms\n",
      "Speed: 2.9ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705542123253656000001-4874858110489948158_png_jpg.rf.d79767eb8378783858ea648a8852c859.jpg: 288x320 1 kidney_stone, 19.5ms\n",
      "Speed: 2.4ms preprocess, 19.5ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63706052409136049800001-4885266517035478638_png_jpg.rf.403057fc6d27ba2b8a1020faf23ea6e8.jpg: 288x320 2 kidney_stones, 19.6ms\n",
      "Speed: 3.3ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63708127596145343100001-4627297054586587945_png_jpg.rf.08b0ce91b3f33c2e333fa6b6a1fd3b19.jpg: 288x320 2 kidney_stones, 17.9ms\n",
      "Speed: 2.5ms preprocess, 17.9ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63709079072689291800001-4862263206834957747_png_jpg.rf.cd218d4ed600ad3b24e4af71077096bd.jpg: 288x320 1 kidney_stone, 17.4ms\n",
      "Speed: 2.5ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63709084528362338400001-4912820873516884035_png_jpg.rf.f90314744947b62d675720abfbabe788.jpg: 288x320 1 kidney_stone, 17.4ms\n",
      "Speed: 2.8ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711136318804220000001-5037705534676835423_png_jpg.rf.7548934bf8faa3895e23ab4416f079f2.jpg: 288x320 2 kidney_stones, 17.3ms\n",
      "Speed: 2.5ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711492298767054500001-4654753270740370732_png_jpg.rf.9c862fae8e8b3d20eaea4dfbc977e94c.jpg: 288x320 6 kidney_stones, 17.3ms\n",
      "Speed: 2.3ms preprocess, 17.3ms inference, 4.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711748853420141600001-4956861441945142931_png_jpg.rf.17718d33d3b046338870e2b5048ae1c4.jpg: 288x320 2 kidney_stones, 17.3ms\n",
      "Speed: 2.6ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712177173773843700001-5180703495942929996_png_jpg.rf.e93c041d68b6e726524f2d1344c079e8.jpg: 288x320 1 kidney_stone, 19.6ms\n",
      "Speed: 2.5ms preprocess, 19.6ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712258135176571000001-4759577505848141624_png_jpg.rf.b91c88cd8bbc6074f8163a75d9c28d3b.jpg: 288x320 1 kidney_stone, 9.4ms\n",
      "Speed: 2.1ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712447732648726100001-5688637637398265537_png_jpg.rf.662c088ba8390b2f998e83343f885879.jpg: 288x320 8 kidney_stones, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63713387527442829100001-4953850576413253802_png_jpg.rf.3c687e765595c73826990914236c246c.jpg: 288x320 2 kidney_stones, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714693213822369100001-5303423760460200335_png_jpg.rf.129f870203e2dd30226016194e3eefc0.jpg: 288x320 1 kidney_stone, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714778964016519000001-5315246250911861092_png_jpg.rf.7b9331ca2327df596e44e33250f8d3a5.jpg: 288x320 1 kidney_stone, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714785261606720600001-5297890145649776819_png_jpg.rf.b1d6426b485945c55414dc7f3a4f036f.jpg: 288x320 1 kidney_stone, 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715282588651483300001-4633048094895900863_png_jpg.rf.4d767c1e9e382ff304d03230490bbf48.jpg: 288x320 1 kidney_stone, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715282588697485900001-4980671363637353986_png_jpg.rf.942e6d1d8c91713ebd262b0d50ebc83b.jpg: 288x320 1 kidney_stone, 19.0ms\n",
      "Speed: 1.6ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715478193571367600001-5500741759278123745_png_jpg.rf.85bf8f585d53d6b1abf90e74571f652a.jpg: 288x320 3 kidney_stones, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716060912810080600001-5177371803856412349_png_jpg.rf.66595d72566632ecf83c25a66fbf0517.jpg: 288x320 1 kidney_stone, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716409318594992900001-4855160927526165509_png_jpg.rf.a9ef656189801fc51d430c16cdc0cfe6.jpg: 288x320 1 kidney_stone, 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716412431841060400001-5514887833163602186_png_jpg.rf.09b76879c6e61bf3e8de9ee6669c6654.jpg: 288x320 1 kidney_stone, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716498031721668100001-4956700971682825541_png_jpg.rf.29537235066c7c0880560e2ddf9b706c.jpg: 288x320 1 kidney_stone, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716499019405160400001-5458996708150830273_png_jpg.rf.ab62109cadfa41271f627c4b6d33bdf5.jpg: 288x320 1 kidney_stone, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716506118862226100001-5296184705475439164_png_jpg.rf.df5142263bbbd253f72ffd9093361538.jpg: 288x320 2 kidney_stones, 17.6ms\n",
      "Speed: 2.2ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717093170609543600001-5475900208815646711_png_jpg.rf.c3b65a7eee4814452137303241df0602.jpg: 288x320 1 kidney_stone, 14.5ms\n",
      "Speed: 2.1ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717702095752440600001-4849669955451581367_png_jpg.rf.60bea159c3babe4188e6a7e7af9c1d83.jpg: 288x320 1 kidney_stone, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717795419239238700001-5010543312669228864_png_jpg.rf.a5329a41a44e18f916c7e0d2ccdba442.jpg: 288x320 1 kidney_stone, 20.4ms\n",
      "Speed: 2.2ms preprocess, 20.4ms inference, 5.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63718233702530473000001-4932089458327885764_png_jpg.rf.5d056a9fa419a38b3cf013c5a4acd9d6.jpg: 288x320 (no detections), 74.2ms\n",
      "Speed: 2.2ms preprocess, 74.2ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63718396246548937900001-4979904738055316795_png_jpg.rf.a8c37077a88165c7440a9174f4e7de43.jpg: 288x320 1 kidney_stone, 46.2ms\n",
      "Speed: 2.8ms preprocess, 46.2ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63720209448267540500001-4892102259156693508_png_jpg.rf.cae7de5a8012ca6a47e1a58e5cf754ac.jpg: 288x320 2 kidney_stones, 16.8ms\n",
      "Speed: 2.7ms preprocess, 16.8ms inference, 10.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63724359033331543500001-4872003896315347521_png_jpg.rf.f6eea33aaf948523c2f84729b25a9e12.jpg: 288x320 1 kidney_stone, 17.6ms\n",
      "Speed: 1.8ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63724531796428573400001-5583374326157765524_png_jpg.rf.6daa696645b8939906b76ec6a356485a.jpg: 288x320 2 kidney_stones, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63726947282502574300001-4970319928017941413_png_jpg.rf.99af32963cd119463adc99e97594a21f.jpg: 288x320 2 kidney_stones, 35.9ms\n",
      "Speed: 2.2ms preprocess, 35.9ms inference, 11.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63728083381661697400001-4679487026905507827_png_jpg.rf.5428fa1c2bbdb04a07cefeb9fdb0245a.jpg: 288x320 1 kidney_stone, 48.8ms\n",
      "Speed: 2.5ms preprocess, 48.8ms inference, 7.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63733253864938749700001-4681200788163641056_png_jpg.rf.66ab082ae6de546b5dcec3741a10002d.jpg: 288x320 1 kidney_stone, 47.4ms\n",
      "Speed: 2.4ms preprocess, 47.4ms inference, 8.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63733253865035755300001-4735710385933343151_png_jpg.rf.5125f3d832afdccaeacd077570d1c518.jpg: 288x320 1 kidney_stone, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 6.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735369110917000400001-4789011592236734083_png_jpg.rf.5d1c4e7ed45b6ee6fdc806d0ba1eb045.jpg: 288x320 1 kidney_stone, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735427803624058800001-4771913503464895901_png_jpg.rf.4689997f30a6d2dbf94a8d3b3fb49bf4.jpg: 288x320 1 kidney_stone, 18.1ms\n",
      "Speed: 1.8ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735865531690592300001-4898255826670355350_png_jpg.rf.1d51373e4d5a21447682d9c3188b17ea.jpg: 288x320 (no detections), 30.2ms\n",
      "Speed: 2.2ms preprocess, 30.2ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63736458322797005700001-5208768444025627150_png_jpg.rf.c33a6719d4a112109220c81c365ecf92.jpg: 288x320 2 kidney_stones, 40.5ms\n",
      "Speed: 3.1ms preprocess, 40.5ms inference, 8.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63736458322910012200001-5596777648389044571_png_jpg.rf.aa4bff6d522d54f8f2cba68374934eb7.jpg: 288x320 1 kidney_stone, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 4.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63737665951722101900001-4980416796139912950_png_jpg.rf.f353747c7833c71191e7c00c1e8766c2.jpg: 288x320 1 kidney_stone, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63737761963388615900001-5365329265867089579_png_jpg.rf.f25ba6213cde91356bf1c9dcef015536.jpg: 288x320 1 kidney_stone, 14.4ms\n",
      "Speed: 3.6ms preprocess, 14.4ms inference, 4.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738098194063336000001-5663074065567912123_png_jpg.rf.37b1dd022a096b834165ee6d6934f231.jpg: 288x320 3 kidney_stones, 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833351756200001-5564599162858324788_png_jpg.rf.43472de584051c332b482d37ffdbae81.jpg: 288x320 (no detections), 19.3ms\n",
      "Speed: 2.2ms preprocess, 19.3ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833519765800001-5338777203487041753_png_jpg.rf.ffb224a50276c7fd005a9a63b11c03d7.jpg: 288x320 (no detections), 11.8ms\n",
      "Speed: 1.8ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833691775600001-5590086017766645144_png_jpg.rf.0a7f335f79875c15042c8609acefc081.jpg: 288x320 2 kidney_stones, 16.6ms\n",
      "Speed: 2.7ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738190974140792500001-4720089151456993587_png_jpg.rf.11473b32d8db11ef403f696b4344c4a9.jpg: 288x320 1 kidney_stone, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738356146609408000001-5713964260076015331_png_jpg.rf.2a3c2b59fbaf56a193d9f14dbb932dbb.jpg: 288x320 1 kidney_stone, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738356146648410200001-5599996945315430757_png_jpg.rf.be14f39eedc9a8124d7548385adc2e9e.jpg: 288x320 1 kidney_stone, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738370133490411800001-5404980644211618423_png_jpg.rf.3a09d97eaf51aa1d631864d196be4c8e.jpg: 288x320 3 kidney_stones, 19.6ms\n",
      "Speed: 1.6ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770518044400001-5249604505762831012_png_jpg.rf.f5fe8e3e350ad44695b18fdad5deecfa.jpg: 288x320 5 kidney_stones, 14.6ms\n",
      "Speed: 1.7ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770596048900001-4824455686483061274_png_jpg.rf.6188a819e2fb98eea23efbb9be751e79.jpg: 288x320 3 kidney_stones, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770632051000001-5568393716624394208_png_jpg.rf.628a9ca8339eddd0fcfd4251406c2f2f.jpg: 288x320 2 kidney_stones, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770669053100001-5253894092784862820_png_jpg.rf.755195eaaea732718c44d5ae55f48038.jpg: 288x320 2 kidney_stones, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738372833265830100001-5268315040608780318_png_jpg.rf.a324465bc4148dd83006ed15e0014ab4.jpg: 288x320 1 kidney_stone, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738372833373836300001-5519774372911833463_png_jpg.rf.188351529ff79195cc4a7f85e5249dae.jpg: 288x320 1 kidney_stone, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345321539100001-5134515060150907763_png_jpg.rf.23d5086bb0af16ec18561b0747bba45e.jpg: 288x320 1 kidney_stone, 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 3.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345351540800001-4833200762892797527_png_jpg.rf.85a9e70dc89f0c6fb76804c9b99586bd.jpg: 288x320 1 kidney_stone, 15.3ms\n",
      "Speed: 2.5ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345419544700001-4764726950619361819_png_jpg.rf.97419e3eca99cb7413678fb1a7b743b2.jpg: 288x320 1 kidney_stone, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345487548600001-5200702102842530817_png_jpg.rf.e0f4ffa8f9621e429e264cedb1d6cf11.jpg: 288x320 1 kidney_stone, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 4.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738701495856739400001-5065202867097533816_png_jpg.rf.ced9aca5815aff9c5ed0bfc426d07fa9.jpg: 288x320 1 kidney_stone, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738712076510918200001-4807005421736379114_png_jpg.rf.41d63d9c3438d6c9f04d09958d992e3e.jpg: 288x320 1 kidney_stone, 15.3ms\n",
      "Speed: 2.0ms preprocess, 15.3ms inference, 4.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738712076544920100001-5262560504645227519_png_jpg.rf.2256c712e5298fb1d068b9b5bd6b260f.jpg: 288x320 1 kidney_stone, 14.3ms\n",
      "Speed: 1.7ms preprocess, 14.3ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738790795811795900001-5522258459602207098_png_jpg.rf.eb9d2068c9f992781bb9814fb156c9e4.jpg: 288x320 1 kidney_stone, 14.3ms\n",
      "Speed: 2.1ms preprocess, 14.3ms inference, 4.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738802300674836400001-5327638065247668022_png_jpg.rf.b2af98a9baeee013c0b25338cd109873.jpg: 288x320 2 kidney_stones, 46.3ms\n",
      "Speed: 2.3ms preprocess, 46.3ms inference, 4.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738957179044522400001-5409943715000019799_png_jpg.rf.2e53c9353b5d8b198b1ce0c679baad07.jpg: 288x320 1 kidney_stone, 27.6ms\n",
      "Speed: 3.2ms preprocess, 27.6ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738957179074524100001-5408839826702883633_png_jpg.rf.22cd2cfe17608bd6192184e5427f4543.jpg: 288x320 1 kidney_stone, 20.6ms\n",
      "Speed: 3.2ms preprocess, 20.6ms inference, 7.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738962850935936000001-5585661387672826890_png_jpg.rf.84352e7d4390c45cf35e145194a23c63.jpg: 288x320 2 kidney_stones, 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739062195410379400001-5653448602067015935_png_jpg.rf.98c0439158bf00599778b20933ad1ff9.jpg: 288x320 1 kidney_stone, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 6.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739062195468382700001-5218664360642519214_png_jpg.rf.010f0c3970dd5d410cff3733975dab0d.jpg: 288x320 1 kidney_stone, 21.1ms\n",
      "Speed: 2.8ms preprocess, 21.1ms inference, 3.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739323961675419500001-4924993173499860596_png_jpg.rf.a0469746d691b54882df3b6bab1f572d.jpg: 288x320 1 kidney_stone, 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739323961724422300001-4739168711678747511_png_jpg.rf.dbeb5256691c7fb946003ceac0fa6a08.jpg: 288x320 1 kidney_stone, 12.6ms\n",
      "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739391821497779300001-5433422355666233277_png_jpg.rf.4ee428144959e7af6db2cff013886aab.jpg: 288x320 4 kidney_stones, 63.1ms\n",
      "Speed: 2.9ms preprocess, 63.1ms inference, 11.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739391821525780900001-5108486655690178522_png_jpg.rf.4caf1c26455d6118d2aa8af9d7e3aa75.jpg: 288x320 4 kidney_stones, 27.5ms\n",
      "Speed: 3.4ms preprocess, 27.5ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739476574564149600001-5439781160937608718_png_jpg.rf.9d41594a6d586bb6256b8b0ecf14c37a.jpg: 288x320 1 kidney_stone, 30.3ms\n",
      "Speed: 2.3ms preprocess, 30.3ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739476574598151500001-4717916049937277621_png_jpg.rf.bdaff9165898dfefa7c60684fc2b0d4c.jpg: 288x320 1 kidney_stone, 21.1ms\n",
      "Speed: 2.3ms preprocess, 21.1ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740171276284352500001-5536100503549537984_png_jpg.rf.6c752f372102c35841b912700635b52c.jpg: 288x320 2 kidney_stones, 23.0ms\n",
      "Speed: 2.8ms preprocess, 23.0ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740182336793977500001-5411618083031416674_png_jpg.rf.e5633e55c0ecfc3f3df68ae9cc6ac411.jpg: 288x320 1 kidney_stone, 47.4ms\n",
      "Speed: 2.4ms preprocess, 47.4ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740603851327033200001-4922091647392565521_png_jpg.rf.bc80c50937c24b91dfea47c556fb48ee.jpg: 288x320 1 kidney_stone, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 2.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740603851401037500001-5653962457778157128_png_jpg.rf.b445c412045a7ec8222fdc54adc5f966.jpg: 288x320 1 kidney_stone, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 4.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740776755054623500001-5096250249767122026_png_jpg.rf.a6d8a3a084e145ba0c32c21f289e90e0.jpg: 288x320 1 kidney_stone, 19.6ms\n",
      "Speed: 2.4ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740776755089625500001-5715333660514809165_png_jpg.rf.cc64673ae8ce9ed7ba042d2717fa0056.jpg: 288x320 1 kidney_stone, 14.5ms\n",
      "Speed: 1.7ms preprocess, 14.5ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580145779300001-5738206214797884235_png_jpg.rf.813f84efb853afe1a7c011cfdbc5bfdb.jpg: 288x320 2 kidney_stones, 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580178781200001-5086422129430942692_png_jpg.rf.c140dab363dde8a657b4e0c672251779.jpg: 288x320 3 kidney_stones, 14.9ms\n",
      "Speed: 2.3ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580218783500001-5558521882885011993_png_jpg.rf.2fb14f6a674b0c7cb403f2b1e8da4215.jpg: 288x320 1 kidney_stone, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580251785300001-5117110417075166265_png_jpg.rf.8d97967148ac132c7b84edf4a7a2cf99.jpg: 288x320 1 kidney_stone, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124799968194600001-5226103760366600348_png_jpg.rf.dd21b253d48ea5394c015dd3c4c7baa1.jpg: 288x320 2 kidney_stones, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800042198800001-5620738533970805933_png_jpg.rf.4fcc14fc70278a025316a0bd3ac8c041.jpg: 288x320 1 kidney_stone, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800130203900001-5588831013201724390_png_jpg.rf.a6a8bd9fc7caa4bea7dbe463acc3e107.jpg: 288x320 2 kidney_stones, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800310214100001-4720519192278742503_png_jpg.rf.bbe6f1a7a488baad44ab26628b67b2c0.jpg: 288x320 2 kidney_stones, 13.7ms\n",
      "Speed: 1.6ms preprocess, 13.7ms inference, 5.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800443221800001-5082720743108815097_png_jpg.rf.2661995bf870c49d3af1255e0df65ed9.jpg: 288x320 1 kidney_stone, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741210469363203700001-5207129079094969383_png_jpg.rf.80f02c0e92710147b575da5b1c8955a8.jpg: 288x320 3 kidney_stones, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 5.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924210744700001-5683531657603489849_png_jpg.rf.aa3cbe8fe88c6f8a7ae446b2a75f3f92.jpg: 288x320 2 kidney_stones, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924248746800001-5006117639889310336_png_jpg.rf.4d8cfc579a4e01ffc2e34e26bb4622f6.jpg: 288x320 1 kidney_stone, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924341752200001-5737252104776306241_png_jpg.rf.c197a107f4dfd4e4687e24d668168a0a.jpg: 288x320 1 kidney_stone, 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924448758300001-5675975946400058540_png_jpg.rf.c5fa641bd708da4cd5a8ace3ecff0fef.jpg: 288x320 1 kidney_stone, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924489760600001-5389065497535856101_png_jpg.rf.0a6c724d073923e3c678bcb59e79980c.jpg: 288x320 1 kidney_stone, 14.8ms\n",
      "Speed: 1.8ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741467279526392800001-4770571118760501971_png_jpg.rf.68ee22f61fbbb636a8586b24471c2690.jpg: 288x320 1 kidney_stone, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741467279569395300001-4987275607072780944_png_jpg.rf.e69a5d34ddb4075908185b3a8244a1d5.jpg: 288x320 1 kidney_stone, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741736586529041200001-5705137549013784232_png_jpg.rf.5898be3563e8ee88ee98154d6be94a55.jpg: 288x320 1 kidney_stone, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 3.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741736586601045300001-5653145914170335853_png_jpg.rf.1ddd466cdd9d53b1d230a680848d709e.jpg: 288x320 1 kidney_stone, 17.8ms\n",
      "Speed: 2.0ms preprocess, 17.8ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741742547533991200001-4692411709729471462_png_jpg.rf.b367d9d12a074a9a2030e1a6761c702c.jpg: 288x320 2 kidney_stones, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741742547563992900001-4813696569989847626_png_jpg.rf.d120dd9eb2922de504cdac0a020eec69.jpg: 288x320 1 kidney_stone, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 3.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741807855851697400001-4668128765309155012_png_jpg.rf.d90c488d99c9f59fe506186cb73e51bb.jpg: 288x320 3 kidney_stones, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741807855890699700001-4907588049082837513_png_jpg.rf.bdfab3beeb6f06e4a84bea1be29819fc.jpg: 288x320 1 kidney_stone, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742411918650702800001-4846811686601840839_png_jpg.rf.c7fdec8546601c5e51e70a059148f2bf.jpg: 288x320 1 kidney_stone, 13.1ms\n",
      "Speed: 1.9ms preprocess, 13.1ms inference, 3.5ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414253972275600001-5472557700106786954_png_jpg.rf.2eaff0bf29d5ec6f8728d7ea0c51a4a1.jpg: 288x320 2 kidney_stones, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254071281200001-5199201186977930207_png_jpg.rf.3712dc035190e6f6f9770a51d306e040.jpg: 288x320 1 kidney_stone, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254117283900001-5038436008074711175_png_jpg.rf.727256debe0b69a6b199349acf584ab0.jpg: 288x320 2 kidney_stones, 22.8ms\n",
      "Speed: 2.1ms preprocess, 22.8ms inference, 12.6ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254175287200001-5117478622886794000_png_jpg.rf.ebca7f6aa7bb26247ad62d333baebc68.jpg: 288x320 1 kidney_stone, 27.4ms\n",
      "Speed: 2.5ms preprocess, 27.4ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742500641013920000001-4736692753633727997_png_jpg.rf.25c7e0a9fe00ed38f512ddd6f63cf3cb.jpg: 288x320 1 kidney_stone, 18.0ms\n",
      "Speed: 1.8ms preprocess, 18.0ms inference, 6.3ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742500641047921900001-5432446600076880623_png_jpg.rf.3980c6219cf1cfc92101f408bbd3a5aa.jpg: 288x320 1 kidney_stone, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742678653846928000001-5308440518832031451_png_jpg.rf.115cdf761943a8faaa63e13139c24f56.jpg: 288x320 1 kidney_stone, 19.4ms\n",
      "Speed: 1.7ms preprocess, 19.4ms inference, 3.4ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456580448800001-4663254346399718819_png_jpg.rf.9c5d4e116bec0275104b14b3f7b5b10e.jpg: 288x320 1 kidney_stone, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456616450900001-5200753212886535539_png_jpg.rf.4c74939464255c6495fddb61d831df4f.jpg: 288x320 1 kidney_stone, 19.1ms\n",
      "Speed: 2.2ms preprocess, 19.1ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456749458500001-4962227765358704856_png_jpg.rf.9e1bcdf85edc4c26b13e14e896cd7fae.jpg: 288x320 1 kidney_stone, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63743022346943480100001-5056079291509312712_png_jpg.rf.04a78eccdbc86bc603e24d4b9224a27d.jpg: 288x320 2 kidney_stones, 20.9ms\n",
      "Speed: 2.7ms preprocess, 20.9ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63743022347069487300001-5100284836990062688_png_jpg.rf.a63070c6a45f65acabf6e15dbb645a92.jpg: 288x320 1 kidney_stone, 19.6ms\n",
      "Speed: 2.6ms preprocess, 19.6ms inference, 6.4ms postprocess per image at shape (1, 3, 288, 320)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model = YOLO(r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\model\\kidney-stone-yolo\\yolov8n-classifier3\\weights\\best.pt')\n",
    "\n",
    "# Run on all images in test folder\n",
    "test_folder = r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images'\n",
    "for img_name in os.listdir(test_folder):\n",
    "    if img_name.endswith('.jpg') or img_name.endswith('.png'):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        results = model(img_path)\n",
    "        # Save results to a text file\n",
    "        with open(os.path.join(test_folder, img_name.replace('.jpg', '.txt').replace('.png', '.txt')), 'w') as f:\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    x, y, w, h = box.xywh[0]\n",
    "                    f.write(f\"{cls} {x} {y} {w} {h}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [01:56<00:00, 193kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Yaswanth Reddy\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'data.yaml' error  'data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:603\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    602\u001b[0m }:\n\u001b[1;32m--> 603\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\data\\utils.py:401\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    (Dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\checks.py:568\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Or your trained model .pt path\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    789\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:153\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\trainer.py:607\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error âŒ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls:\n\u001b[0;32m    609\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding class names with single class.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'data.yaml' error  'data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")  # Or your trained model .pt path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kidney.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s-classifier, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=kidney-stone-yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=kidney-stone-yolo\\yolov8s-classifier, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 19.42.9 MB/s, size: 15.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\train\\labels.cache... 1054 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1054/1054 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 16.65.7 MB/s, size: 17.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\labels.cache... 123 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to kidney-stone-yolo\\yolov8s-classifier\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mkidney-stone-yolo\\yolov8s-classifier\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.674G       2.47      2.671      1.146         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:22<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.578      0.387      0.365      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30     0.762G      2.397      1.321      1.099         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.552      0.458      0.362      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30     0.762G      2.433      1.212      1.106         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.533      0.409      0.366      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30     0.762G      2.278      1.128      1.087         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.601      0.425      0.412      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30     0.762G      2.242      1.109      1.058         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.602      0.503      0.437      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30     0.762G      2.249      1.079      1.063         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.601      0.397      0.395      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30     0.762G       2.21      1.048      1.061         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.705      0.515      0.539      0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30     0.762G      2.285      1.112      1.081         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.682      0.509      0.513      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30     0.762G       2.17      1.065      1.043         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.717      0.597      0.605      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30     0.762G      2.178      1.046      1.055          8        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.725      0.502      0.471      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30     0.762G       2.15      1.095      1.062         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.717      0.499      0.533      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30     0.762G      2.071      1.016      1.039         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.733      0.471       0.54      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30     0.762G      2.119      1.003      1.031         36        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.665      0.538      0.555      0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30     0.762G      2.083      0.937      1.033         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.645      0.495      0.505      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30     0.762G       2.06     0.9456      1.034         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.703      0.494      0.532      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30     0.762G      2.033     0.9427      1.033         45        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.68      0.563      0.579      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30     0.762G      2.026     0.9243       1.01         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.791      0.499      0.575      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30     0.762G      1.994     0.8868      1.012         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.655      0.575      0.558      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30     0.762G      1.962     0.9046      1.018         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.699      0.591      0.617      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30     0.762G      1.962     0.8588      1.005         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.714      0.582      0.609      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30     0.762G      1.903     0.8486      1.002         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.647      0.542       0.54      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30     0.762G      1.954      0.893      1.014          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.71      0.591      0.603      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30     0.762G      1.877     0.8291      1.002         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.695       0.56      0.594      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30     0.762G      1.909     0.8405     0.9993         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.696      0.578      0.592      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30     0.762G      1.888      0.843      1.004          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.741      0.545      0.588      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30     0.762G      1.886     0.8242     0.9896          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.714      0.538      0.594      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30     0.762G       1.82     0.8038     0.9832         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.716       0.59      0.599       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30     0.762G      1.852     0.8092     0.9754          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.751      0.572      0.614      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30     0.762G      1.826     0.7852     0.9685          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.761      0.578      0.622      0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30     0.762G      1.776     0.7642     0.9799          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.733        0.6      0.632      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.156 hours.\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8s-classifier\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8s-classifier\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating kidney-stone-yolo\\yolov8s-classifier\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.761      0.578      0.623      0.259\n",
      "Speed: 0.2ms preprocess, 5.1ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mkidney-stone-yolo\\yolov8s-classifier\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021E3A5EFC50>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
       "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,     0.96429,\n",
       "            0.96429,     0.96429,     0.96429,     0.96429,     0.96429,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,\n",
       "            0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,\n",
       "            0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.94737,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,\n",
       "            0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93902,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,\n",
       "            0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.93182,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,\n",
       "            0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92806,     0.92199,     0.92199,     0.92199,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.91781,     0.90667,     0.90667,\n",
       "            0.90667,     0.90667,     0.90667,     0.90667,     0.90667,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,     0.90446,\n",
       "            0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,     0.89091,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,      0.8869,     0.87209,\n",
       "            0.87209,     0.87209,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86592,     0.86188,     0.86188,     0.86188,     0.84211,     0.84211,     0.84211,\n",
       "            0.84211,     0.84211,     0.84211,     0.84211,     0.84211,     0.84211,     0.84211,     0.84211,     0.84211,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.84103,     0.83756,\n",
       "            0.83756,     0.83756,     0.82673,     0.82673,     0.82673,     0.82673,     0.82673,     0.82673,     0.82439,     0.82439,     0.82439,     0.82439,     0.82439,     0.82439,     0.81429,     0.81429,     0.81429,     0.81429,     0.81429,     0.81429,     0.81221,     0.81221,     0.81221,\n",
       "            0.81221,     0.81221,     0.81221,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,     0.80365,      0.8018,      0.8018,      0.8018,      0.8018,      0.8018,      0.8018,      0.8018,     0.79911,     0.79911,     0.79911,     0.79646,\n",
       "            0.79646,     0.79646,     0.77778,     0.77778,     0.77778,     0.77778,     0.77778,     0.77778,     0.77731,     0.77731,     0.77731,     0.77731,     0.77731,     0.77731,     0.77731,     0.77731,     0.77731,     0.77178,     0.77178,     0.77178,     0.76955,     0.76955,     0.76955,\n",
       "            0.76113,     0.76113,     0.76113,     0.74704,     0.74704,     0.74704,     0.73745,     0.73745,     0.73745,     0.73745,     0.73745,     0.73745,     0.73745,     0.73282,     0.73282,     0.73282,     0.72556,     0.72556,     0.72556,     0.71062,     0.71062,     0.71062,     0.70909,\n",
       "            0.70909,     0.70909,     0.70107,     0.70107,     0.70107,     0.70107,     0.70107,     0.70107,     0.69965,     0.69965,     0.69965,     0.69338,     0.69338,     0.69338,     0.68966,     0.68966,     0.68966,     0.65902,     0.65902,     0.65902,     0.65273,     0.65273,     0.65273,\n",
       "            0.65273,     0.65273,     0.65273,     0.64557,     0.64557,     0.64557,     0.64557,     0.64465,     0.64465,     0.64465,     0.62805,     0.62805,     0.62805,     0.62727,     0.62727,     0.62727,     0.62462,     0.62462,     0.62462,     0.58217,     0.58217,     0.58217,     0.48387,\n",
       "            0.48387,     0.48387,     0.48284,     0.48284,     0.48284,     0.46593,     0.46593,     0.46593,     0.40883,     0.40883,     0.40883,     0.23543,     0.23475,     0.23407,     0.23338,      0.2327,     0.23201,     0.23133,     0.23064,     0.22996,     0.22927,     0.22859,     0.22791,\n",
       "            0.22722,     0.22654,     0.22585,     0.22517,     0.22448,      0.2238,     0.22311,     0.22243,     0.22175,     0.22106,     0.22038,     0.21969,     0.21901,     0.21832,     0.21764,     0.21696,     0.21627,     0.21559,      0.2149,     0.21422,     0.21353,     0.21285,     0.21216,\n",
       "            0.21148,      0.2108,     0.21011,     0.20943,     0.20874,     0.20806,     0.20737,     0.20669,       0.206,     0.20532,     0.20464,     0.20395,     0.20327,     0.20258,      0.2019,     0.20121,     0.20053,     0.19985,     0.19916,     0.19848,     0.19779,     0.19711,     0.19642,\n",
       "            0.19574,     0.19505,     0.19437,     0.19369,       0.193,     0.19232,     0.19163,     0.19095,     0.19026,     0.18958,     0.18889,     0.18821,     0.18753,     0.18684,     0.18616,     0.18547,     0.18479,      0.1841,     0.18342,     0.18274,     0.18205,     0.18137,     0.18068,\n",
       "               0.18,     0.17931,     0.17863,     0.17794,     0.17726,     0.17658,     0.17589,     0.17521,     0.17452,     0.17384,     0.17315,     0.17247,     0.17178,      0.1711,     0.17042,     0.16973,     0.16905,     0.16836,     0.16768,     0.16699,     0.16631,     0.16563,     0.16494,\n",
       "            0.16426,     0.16357,     0.16289,      0.1622,     0.16152,     0.16083,     0.16015,     0.15947,     0.15878,      0.1581,     0.15741,     0.15673,     0.15604,     0.15536,     0.15467,     0.15399,     0.15331,     0.15262,     0.15194,     0.15125,     0.15057,     0.14988,      0.1492,\n",
       "            0.14852,     0.14783,     0.14715,     0.14646,     0.14578,     0.14509,     0.14441,     0.14372,     0.14304,     0.14236,     0.14167,     0.14099,      0.1403,     0.13962,     0.13893,     0.13825,     0.13756,     0.13688,      0.1362,     0.13551,     0.13483,     0.13414,     0.13346,\n",
       "            0.13277,     0.13209,     0.13141,     0.13072,     0.13004,     0.12935,     0.12867,     0.12798,      0.1273,     0.12661,     0.12593,     0.12525,     0.12456,     0.12388,     0.12319,     0.12251,     0.12182,     0.12114,     0.12045,     0.11977,     0.11909,      0.1184,     0.11772,\n",
       "            0.11703,     0.11635,     0.11566,     0.11498,      0.1143,     0.11361,     0.11293,     0.11224,     0.11156,     0.11087,     0.11019,      0.1095,     0.10882,     0.10814,     0.10745,     0.10677,     0.10608,      0.1054,     0.10471,     0.10403,     0.10334,     0.10266,     0.10198,\n",
       "            0.10129,     0.10061,    0.099923,    0.099238,    0.098554,    0.097869,    0.097185,    0.096501,    0.095816,    0.095132,    0.094447,    0.093763,    0.093079,    0.092394,     0.09171,    0.091025,    0.090341,    0.089657,    0.088972,    0.088288,    0.087603,    0.086919,    0.086235,\n",
       "            0.08555,    0.084866,    0.084181,    0.083497,    0.082813,    0.082128,    0.081444,    0.080759,    0.080075,    0.079391,    0.078706,    0.078022,    0.077337,    0.076653,    0.075969,    0.075284,      0.0746,    0.073915,    0.073231,    0.072547,    0.071862,    0.071178,    0.070493,\n",
       "           0.069809,    0.069125,     0.06844,    0.067756,    0.067071,    0.066387,    0.065703,    0.065018,    0.064334,    0.063649,    0.062965,    0.062281,    0.061596,    0.060912,    0.060227,    0.059543,    0.058859,    0.058174,     0.05749,    0.056805,    0.056121,    0.055437,    0.054752,\n",
       "           0.054068,    0.053383,    0.052699,    0.052015,     0.05133,    0.050646,    0.049961,    0.049277,    0.048593,    0.047908,    0.047224,    0.046539,    0.045855,    0.045171,    0.044486,    0.043802,    0.043117,    0.042433,    0.041748,    0.041064,     0.04038,    0.039695,    0.039011,\n",
       "           0.038326,    0.037642,    0.036958,    0.036273,    0.035589,    0.034904,     0.03422,    0.033536,    0.032851,    0.032167,    0.031482,    0.030798,    0.030114,    0.029429,    0.028745,     0.02806,    0.027376,    0.026692,    0.026007,    0.025323,    0.024638,    0.023954,     0.02327,\n",
       "           0.022585,    0.021901,    0.021216,    0.020532,    0.019848,    0.019163,    0.018479,    0.017794,     0.01711,    0.016426,    0.015741,    0.015057,    0.014372,    0.013688,    0.013004,    0.012319,    0.011635,     0.01095,    0.010266,   0.0095816,   0.0088972,   0.0082128,   0.0075284,\n",
       "           0.006844,   0.0061596,   0.0054752,   0.0047908,   0.0041064,    0.003422,   0.0027376,   0.0020532,   0.0013688,   0.0006844,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.34662,     0.34662,     0.39247,     0.42135,     0.44187,      0.4543,     0.46529,     0.47276,     0.47867,     0.49028,     0.49746,     0.50209,     0.50802,     0.51226,     0.51605,     0.51866,     0.52134,     0.52443,     0.52611,     0.52907,     0.53133,     0.53377,     0.53591,\n",
       "            0.53719,     0.53941,     0.54301,     0.54345,     0.54524,     0.54623,     0.54893,     0.55135,      0.5535,     0.55308,     0.55608,     0.55849,     0.56188,     0.56414,     0.56619,     0.56731,     0.56888,     0.57002,      0.5714,     0.57352,     0.57528,     0.57763,       0.579,\n",
       "            0.57929,     0.57959,      0.5816,      0.5832,     0.58585,     0.58787,     0.59041,     0.59113,     0.59271,     0.59668,     0.59802,     0.59884,     0.60065,     0.60123,     0.60237,     0.60273,     0.60308,     0.60389,     0.60512,     0.60701,     0.60929,     0.60992,     0.61059,\n",
       "            0.60994,     0.60963,     0.61022,     0.61071,     0.61249,      0.6137,     0.61403,     0.61436,     0.61727,     0.61783,     0.61929,     0.61981,     0.62073,     0.62143,     0.62334,     0.62453,     0.62661,     0.62695,     0.62728,      0.6277,      0.6282,      0.6295,     0.62999,\n",
       "             0.6313,     0.63205,     0.63179,     0.63123,     0.63067,     0.63016,     0.63062,     0.63109,     0.63158,     0.63109,      0.6306,     0.63011,     0.63091,     0.62949,     0.63135,     0.63184,     0.63207,     0.63231,     0.63254,     0.63295,     0.63379,     0.63464,     0.63501,\n",
       "            0.63536,     0.63705,     0.63683,     0.63581,     0.63596,     0.63447,     0.63525,     0.63557,      0.6358,     0.63604,     0.63628,     0.63824,      0.6374,     0.63657,     0.63581,      0.6351,     0.63439,     0.63424,     0.63456,     0.63487,     0.63535,      0.6361,     0.63678,\n",
       "            0.63614,     0.63702,     0.63739,     0.63775,     0.63825,     0.63895,     0.63965,     0.64052,     0.64109,      0.6412,     0.64132,     0.64143,     0.64155,     0.64166,     0.64178,     0.64189,     0.64201,     0.64221,     0.64246,     0.64271,     0.64295,     0.64426,     0.64454,\n",
       "            0.64482,     0.64511,     0.64538,     0.64566,     0.64594,     0.64836,     0.64987,     0.64984,     0.64855,     0.64836,     0.64858,     0.64879,       0.649,     0.64921,     0.64998,     0.65001,     0.64953,     0.64904,     0.64855,     0.64823,      0.6491,     0.65054,     0.65112,\n",
       "            0.65017,     0.64921,     0.64983,     0.64861,     0.64581,     0.64607,     0.64633,     0.64658,     0.64703,     0.64798,      0.6492,     0.64979,     0.64955,     0.64884,     0.64812,     0.64796,     0.64701,     0.64803,     0.64863,     0.65018,     0.65061,     0.65138,     0.65218,\n",
       "            0.65243,     0.65267,     0.65292,     0.65089,     0.65123,     0.65156,      0.6519,      0.6523,     0.65271,     0.65313,     0.65356,       0.654,     0.65378,      0.6531,     0.65243,      0.6522,     0.65318,      0.6535,     0.65383,     0.65132,     0.64962,     0.64995,     0.65028,\n",
       "            0.65061,     0.65115,     0.65169,     0.65334,     0.65252,     0.65394,     0.65417,      0.6544,     0.65463,     0.65485,     0.65509,     0.65535,     0.65562,     0.65589,     0.65616,     0.65635,     0.65652,     0.65669,     0.65687,     0.65704,     0.65722,     0.65725,     0.65693,\n",
       "            0.65661,     0.65629,     0.65597,     0.65565,     0.65533,       0.655,     0.65632,     0.65711,     0.65738,      0.6575,     0.65761,     0.65773,     0.65785,     0.65796,     0.65808,     0.65819,     0.65831,     0.65842,     0.65722,     0.65629,     0.65697,     0.65676,     0.65595,\n",
       "            0.65514,     0.65499,     0.65517,     0.65536,     0.65554,     0.65572,      0.6559,     0.65655,     0.65675,     0.65599,     0.65524,     0.65456,     0.65398,      0.6534,     0.65283,     0.65234,     0.65209,     0.65185,      0.6516,     0.65135,     0.65111,     0.65086,     0.65061,\n",
       "            0.65037,     0.65012,     0.65025,     0.65073,      0.6509,     0.64843,     0.64753,     0.64662,     0.64762,     0.64783,     0.64804,     0.64825,     0.64845,     0.64866,     0.64883,       0.649,     0.64917,     0.64934,     0.64952,     0.64969,     0.64986,     0.65006,     0.65025,\n",
       "            0.65044,     0.65063,     0.65083,     0.65106,     0.65154,     0.65202,     0.65301,     0.65294,     0.65235,     0.65175,     0.65116,     0.65171,     0.65104,     0.65037,      0.6497,     0.65027,     0.65074,     0.65034,     0.64993,     0.64953,     0.64912,     0.64871,     0.64832,\n",
       "            0.64804,     0.64776,     0.64748,     0.64719,     0.64691,     0.64663,     0.64634,     0.64606,     0.64598,      0.6463,     0.64663,     0.64695,     0.64536,     0.64174,     0.64128,     0.64081,     0.64034,     0.63987,     0.63962,      0.6398,     0.63999,     0.64018,     0.64037,\n",
       "            0.64055,     0.64074,     0.64089,     0.64103,     0.64118,     0.64133,     0.64148,     0.64163,     0.64177,     0.64192,     0.63816,     0.63923,      0.6367,     0.63615,      0.6356,     0.63504,     0.63449,     0.63476,      0.6356,     0.63601,     0.63642,     0.63665,     0.63682,\n",
       "            0.63698,     0.63715,     0.63731,     0.63747,     0.63764,     0.63755,     0.63709,     0.63664,     0.63618,     0.63572,     0.63526,     0.63355,     0.63364,     0.63348,     0.63332,     0.63316,       0.633,     0.63284,     0.63268,     0.63252,     0.63235,     0.63219,     0.63203,\n",
       "            0.63187,     0.63171,     0.63155,     0.63139,     0.63122,      0.6307,     0.63003,     0.62936,      0.6287,     0.62915,      0.6298,     0.63005,     0.63029,     0.63054,     0.63079,     0.63157,     0.62987,     0.63002,     0.62731,     0.62529,     0.62472,     0.62415,     0.62357,\n",
       "              0.623,     0.62101,     0.61939,     0.61564,     0.61518,     0.61472,     0.61426,     0.61379,     0.61333,     0.61081,     0.61113,     0.61174,     0.61206,     0.61237,     0.61268,     0.61425,     0.61549,      0.6139,     0.61423,     0.61456,      0.6149,     0.61381,     0.61218,\n",
       "            0.61186,     0.61155,     0.61123,     0.61092,      0.6106,     0.61029,     0.60997,     0.60966,     0.60759,     0.60473,     0.60329,     0.60233,     0.60138,     0.60171,     0.60233,     0.60277,     0.60318,      0.6036,     0.60139,     0.60201,     0.60233,     0.60264,     0.60295,\n",
       "            0.60329,     0.60392,     0.60442,     0.60413,     0.60384,     0.60355,     0.60326,     0.60297,     0.60268,     0.60239,      0.6021,     0.60181,     0.60108,     0.59962,     0.59896,     0.59937,     0.59979,     0.59927,      0.5978,      0.5966,     0.59562,     0.59463,     0.59365,\n",
       "            0.59266,     0.59168,     0.59034,     0.58886,     0.58626,     0.58652,     0.58862,     0.58787,     0.58711,     0.58636,     0.57766,     0.57461,     0.57215,     0.57164,     0.57112,     0.57061,     0.57009,     0.56949,     0.56794,     0.56664,     0.56695,     0.56725,     0.56756,\n",
       "            0.56808,      0.5682,     0.56277,     0.56232,     0.56188,     0.56143,     0.56098,     0.56053,     0.56008,      0.5584,     0.55689,      0.5572,      0.5575,     0.55781,     0.55703,     0.55544,      0.5556,     0.55535,     0.55428,     0.55321,     0.55245,     0.55181,     0.55117,\n",
       "            0.55053,     0.54988,     0.54843,     0.54681,     0.53739,     0.53743,     0.53778,     0.53812,     0.53665,     0.53335,     0.53005,     0.52672,     0.52338,     0.52108,      0.5194,     0.51771,     0.51603,     0.51434,     0.51264,     0.50827,     0.50742,     0.50656,     0.50571,\n",
       "             0.5041,     0.50239,      0.4957,     0.49222,     0.48872,     0.48695,     0.48499,     0.48084,     0.47907,     0.47793,     0.47722,     0.47651,      0.4758,     0.47508,     0.47231,     0.47095,     0.47035,     0.46975,     0.46915,     0.46855,     0.46795,     0.46307,     0.46162,\n",
       "            0.45777,     0.45798,     0.45725,     0.45652,     0.45578,     0.45505,     0.44894,     0.44341,     0.44258,     0.44175,     0.44092,     0.44011,     0.43936,     0.43861,     0.43786,      0.4371,     0.43159,     0.42867,     0.42714,     0.42562,     0.42193,     0.42057,     0.41928,\n",
       "            0.41801,     0.41691,      0.4158,      0.4147,     0.41186,     0.40797,     0.40155,     0.39959,     0.39618,     0.39064,     0.38976,     0.38887,     0.38798,     0.38692,     0.38289,     0.37939,     0.37668,     0.37698,     0.37745,     0.37777,     0.37808,      0.3782,     0.37547,\n",
       "            0.37191,     0.36779,     0.36574,     0.36482,     0.36389,     0.36297,     0.35833,     0.35879,     0.35781,     0.35406,     0.35125,     0.34718,     0.34589,     0.34494,     0.34399,     0.34304,     0.33621,     0.33352,     0.33229,     0.33105,     0.32945,      0.3253,     0.32238,\n",
       "            0.31659,     0.31579,     0.31499,     0.31418,     0.31338,     0.31191,     0.30894,     0.30471,     0.30217,     0.29992,     0.29891,     0.29801,     0.29711,      0.2962,     0.29592,     0.28691,     0.27811,     0.27347,     0.27191,     0.27035,     0.26437,     0.25997,      0.2568,\n",
       "            0.25421,     0.25182,     0.24879,     0.24113,      0.2387,     0.22386,     0.22061,     0.21812,      0.2161,     0.21411,     0.21143,     0.20316,     0.19978,     0.19688,     0.19432,     0.19273,      0.1917,     0.19068,     0.18965,     0.18862,      0.1836,     0.18342,     0.18194,\n",
       "            0.18045,     0.17896,     0.17574,     0.17324,     0.17219,     0.17114,     0.17009,     0.16904,     0.16244,     0.16067,      0.1589,     0.15082,      0.1422,     0.14039,     0.13857,     0.13656,     0.13383,     0.13188,     0.13213,     0.13072,     0.12888,     0.12704,       0.126,\n",
       "            0.12507,     0.12415,     0.12322,      0.1223,     0.12132,      0.1176,      0.1089,     0.10608,    0.097121,    0.093574,    0.091662,    0.089745,    0.076757,    0.075979,      0.0752,    0.074421,    0.073641,    0.072861,    0.072079,    0.071298,    0.069111,    0.066756,    0.065219,\n",
       "           0.064657,    0.064094,    0.063531,    0.062968,    0.062404,     0.06184,    0.061276,    0.060711,    0.060146,     0.05952,    0.058671,    0.057822,    0.056972,    0.056121,    0.055269,    0.054417,    0.047759,    0.047007,    0.046255,    0.045503,    0.044749,    0.043995,    0.043241,\n",
       "           0.042486,    0.041531,    0.040431,    0.039329,    0.038226,    0.037122,    0.036109,    0.035433,    0.034756,    0.034079,    0.033402,    0.032724,    0.032046,    0.031367,    0.030688,    0.028531,    0.024436,    0.020325,    0.017035,    0.014552,    0.012223,    0.012088,    0.011952,\n",
       "           0.011817,    0.011681,    0.011546,     0.01141,    0.011275,    0.011139,    0.011003,    0.010868,    0.010732,    0.010596,    0.010461,    0.010325,    0.010189,    0.010053,   0.0099177,    0.009782,   0.0096462,   0.0095103,   0.0093745,   0.0092386,   0.0091028,   0.0089669,    0.008831,\n",
       "           0.008695,   0.0085591,   0.0084231,   0.0082872,   0.0081511,   0.0080151,   0.0078791,    0.007743,    0.007607,   0.0074709,   0.0073347,   0.0071986,   0.0070625,   0.0069263,   0.0067901,   0.0066539,   0.0065177,   0.0063814,   0.0062452,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.23562,     0.23562,     0.28011,     0.31047,     0.33328,     0.34763,     0.36068,     0.36974,     0.37702,     0.39162,     0.40086,     0.40691,       0.416,     0.42172,     0.42688,     0.43046,     0.43417,     0.43848,     0.44082,     0.44499,     0.44821,     0.45169,     0.45476,\n",
       "            0.45661,     0.45982,     0.46509,     0.46573,     0.46997,     0.47144,     0.47547,     0.47911,     0.48238,     0.48345,     0.48981,     0.49357,     0.49888,     0.50246,     0.50573,     0.50752,     0.51003,     0.51187,      0.5141,     0.51755,     0.52042,     0.52427,     0.52654,\n",
       "            0.52702,     0.52751,     0.53084,     0.53352,     0.53798,     0.54139,     0.54572,     0.54695,     0.54966,     0.55653,     0.55886,     0.56031,     0.56348,      0.5645,     0.56651,     0.56714,     0.56777,      0.5692,      0.5714,     0.57477,     0.57887,     0.58001,     0.58122,\n",
       "             0.5815,     0.58202,     0.58309,     0.58399,     0.58724,     0.58948,     0.59009,      0.5907,      0.5961,     0.59714,     0.59988,     0.60086,     0.60258,     0.60391,     0.60752,      0.6098,     0.61377,     0.61442,     0.61506,     0.61587,     0.61684,     0.61934,     0.62029,\n",
       "            0.62283,     0.62429,     0.62439,     0.62409,     0.62378,     0.62354,     0.62445,     0.62536,     0.62701,     0.62675,     0.62648,     0.62622,     0.62799,     0.62821,     0.63194,     0.63291,     0.63339,     0.63386,     0.63433,     0.63514,     0.63684,     0.63855,     0.63931,\n",
       "            0.64002,     0.64346,     0.64423,     0.64369,     0.64445,     0.64464,     0.64625,     0.64691,      0.6474,     0.64789,     0.64838,     0.65267,     0.65223,     0.65179,      0.6514,     0.65103,     0.65066,     0.65084,     0.65151,     0.65218,     0.65318,     0.65476,     0.65623,\n",
       "            0.65834,     0.66024,     0.66102,      0.6618,     0.66288,     0.66438,      0.6659,     0.66779,     0.66903,     0.66928,     0.66953,     0.66978,     0.67003,     0.67029,     0.67054,     0.67079,     0.67104,     0.67148,     0.67202,     0.67257,     0.67311,     0.67597,     0.67659,\n",
       "            0.67722,     0.67785,     0.67846,     0.67907,     0.67968,     0.68507,     0.68845,     0.68938,     0.68875,     0.68893,     0.68941,     0.68989,     0.69037,     0.69085,     0.69259,     0.69323,     0.69299,     0.69275,     0.69252,     0.69256,     0.69455,     0.69785,     0.69955,\n",
       "             0.6991,     0.69864,     0.70091,     0.70032,     0.69919,      0.6998,     0.70041,     0.70101,     0.70206,      0.7043,     0.70718,     0.70858,     0.70888,     0.70854,     0.70821,     0.71021,     0.71063,      0.7131,     0.71454,     0.71832,     0.71936,     0.72125,     0.72323,\n",
       "            0.72383,     0.72444,     0.72504,     0.72463,     0.72547,      0.7263,     0.72713,     0.72813,     0.72916,      0.7302,     0.73129,     0.73238,     0.73265,     0.73235,     0.73205,     0.73261,     0.73509,     0.73592,     0.73675,     0.73622,     0.73576,      0.7366,     0.73744,\n",
       "            0.73829,     0.73969,     0.74108,     0.74676,     0.74832,     0.75208,     0.75268,     0.75329,     0.75389,     0.75449,     0.75511,     0.75582,     0.75654,     0.75725,     0.75796,     0.75847,     0.75893,      0.7594,     0.75986,     0.76033,      0.7608,      0.7611,     0.76096,\n",
       "            0.76083,      0.7607,     0.76057,     0.76043,      0.7603,     0.76017,     0.76375,     0.76589,     0.76663,     0.76695,     0.76726,     0.76758,      0.7679,     0.76821,     0.76853,     0.76884,     0.76916,     0.76947,     0.76905,     0.76915,     0.77102,     0.77159,     0.77127,\n",
       "            0.77094,     0.77117,     0.77168,     0.77219,      0.7727,     0.77321,     0.77371,      0.7755,     0.77714,     0.77684,     0.77654,     0.77627,     0.77605,     0.77582,     0.77559,      0.7754,      0.7753,      0.7752,      0.7751,       0.775,     0.77491,     0.77481,     0.77471,\n",
       "            0.77461,     0.77452,     0.77517,     0.77653,     0.77767,      0.7767,     0.77634,     0.77598,     0.77962,     0.78023,     0.78083,     0.78143,     0.78204,     0.78264,     0.78314,     0.78364,     0.78414,     0.78464,     0.78514,     0.78564,     0.78615,     0.78672,     0.78729,\n",
       "            0.78785,     0.78842,     0.78898,     0.78966,     0.79108,     0.79251,     0.79544,      0.7963,     0.79609,     0.79587,     0.79565,     0.79897,     0.79872,     0.79847,     0.79823,     0.80012,     0.80177,     0.80162,     0.80148,     0.80133,     0.80118,     0.80104,     0.80089,\n",
       "            0.80079,     0.80069,     0.80058,     0.80048,     0.80038,     0.80028,     0.80017,     0.80007,     0.80033,     0.80132,     0.80232,     0.80332,     0.80304,     0.80173,     0.80155,     0.80138,     0.80121,     0.80104,     0.80112,      0.8017,     0.80229,     0.80288,     0.80347,\n",
       "            0.80405,     0.80464,     0.80511,     0.80558,     0.80605,     0.80651,     0.80698,     0.80745,     0.80791,     0.80838,     0.81046,     0.81423,      0.8134,      0.8132,     0.81301,     0.81281,     0.81262,     0.81451,      0.8173,     0.81865,        0.82,     0.82078,     0.82133,\n",
       "            0.82187,     0.82242,     0.82297,     0.82352,     0.82406,     0.82433,     0.82418,     0.82402,     0.82387,     0.82372,     0.82356,     0.82596,     0.82669,     0.82664,     0.82658,     0.82653,     0.82647,     0.82642,     0.82637,     0.82631,     0.82626,     0.82621,     0.82615,\n",
       "             0.8261,     0.82605,     0.82599,     0.82594,     0.82589,     0.82571,     0.82549,     0.82526,     0.82504,     0.82698,     0.82924,      0.8301,     0.83096,     0.83181,     0.83267,     0.83737,     0.83785,     0.84079,     0.83995,     0.83932,     0.83914,     0.83896,     0.83878,\n",
       "             0.8386,     0.84083,     0.84149,     0.84032,     0.84017,     0.84003,     0.83988,     0.83973,     0.83959,     0.83879,     0.84083,     0.84316,     0.84437,     0.84555,     0.84672,     0.85275,     0.85755,     0.86125,     0.86257,     0.86388,      0.8652,     0.86557,     0.86513,\n",
       "            0.86504,     0.86495,     0.86487,     0.86478,     0.86469,     0.86461,     0.86452,     0.86443,     0.86386,     0.86306,     0.86266,     0.86239,     0.86212,     0.86415,     0.86671,     0.86854,     0.87026,     0.87199,     0.87381,     0.87644,     0.87778,     0.87911,     0.88044,\n",
       "            0.88189,     0.88457,      0.8869,     0.88683,     0.88676,     0.88669,     0.88662,     0.88655,     0.88648,     0.88641,     0.88634,     0.88627,     0.88609,     0.88574,     0.88632,     0.88816,     0.88999,     0.89074,      0.8904,     0.89012,     0.88989,     0.88966,     0.88943,\n",
       "            0.88919,     0.88896,     0.88864,     0.88829,     0.88767,      0.8919,     0.90433,     0.90418,     0.90402,     0.90386,     0.90202,     0.90136,     0.90657,     0.90646,     0.90635,     0.90625,     0.90614,     0.90601,     0.90569,     0.90562,      0.9072,     0.90877,     0.91035,\n",
       "            0.91305,     0.91766,     0.91664,     0.91656,     0.91647,     0.91639,      0.9163,     0.91622,     0.91613,     0.91581,     0.91629,     0.91795,     0.91961,     0.92128,     0.92182,     0.92154,     0.92566,     0.92794,     0.92776,     0.92759,     0.92746,     0.92735,     0.92724,\n",
       "            0.92713,     0.92702,     0.92678,      0.9265,     0.92486,     0.92669,     0.92874,      0.9308,     0.93155,     0.93101,     0.93047,     0.92991,     0.92935,     0.92895,     0.92867,     0.92837,     0.92808,     0.92779,     0.92749,     0.92671,     0.92656,      0.9264,     0.92625,\n",
       "            0.92596,     0.92565,     0.92441,     0.92375,     0.92308,     0.92274,     0.92236,     0.92155,     0.92119,     0.92097,     0.92082,     0.92068,     0.92054,     0.92039,     0.91983,     0.91955,     0.91943,      0.9193,     0.91918,     0.91906,     0.91893,     0.91791,      0.9176,\n",
       "            0.92065,     0.92516,     0.92502,     0.92488,     0.92473,     0.92459,     0.92336,     0.92222,     0.92205,     0.92187,      0.9217,     0.92153,     0.92137,     0.92121,     0.92105,     0.92089,      0.9197,     0.91906,     0.91873,     0.91839,     0.91755,     0.91724,     0.91695,\n",
       "            0.91666,      0.9164,     0.91614,     0.91589,     0.91522,     0.91428,     0.91271,     0.91222,     0.91136,     0.90994,     0.90971,     0.90947,     0.90924,      0.9192,     0.91823,     0.91738,     0.91671,       0.922,     0.92766,     0.93154,     0.93541,     0.93899,     0.93848,\n",
       "             0.9378,     0.93699,     0.93659,      0.9364,     0.93622,     0.93603,      0.9367,     0.94301,     0.94715,      0.9465,     0.94601,     0.94529,     0.94505,     0.94488,      0.9447,     0.94453,     0.94325,     0.94273,     0.94249,     0.94224,     0.94193,     0.94109,     0.94049,\n",
       "            0.93928,      0.9391,     0.93893,     0.93876,     0.93858,     0.93826,      0.9376,     0.93664,     0.93605,     0.93553,     0.93528,     0.93507,     0.93485,     0.93463,     0.94996,     0.94822,     0.96351,     0.96282,     0.96258,     0.96234,     0.96139,     0.96067,     0.96013,\n",
       "            0.95969,     0.95927,     0.95872,     0.95729,     0.95681,     0.95372,     0.95298,     0.95241,     0.95193,     0.95146,      0.9508,     0.94868,     0.94776,     0.94695,     0.94622,     0.94575,     0.94545,     0.94514,     0.94483,     0.94452,     0.95705,     0.97051,     0.97025,\n",
       "            0.96999,     0.96973,     0.96913,     0.96867,     0.96846,     0.96825,     0.96805,     0.96784,     0.96646,     0.96607,     0.96567,     0.96374,     0.96147,     0.96094,     0.96041,     0.95982,     0.95896,     0.96579,     0.99426,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,     0.65231,\n",
       "            0.65231,     0.65231,     0.65231,     0.65231,     0.64923,     0.64923,     0.64923,     0.64923,     0.64923,     0.64615,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,\n",
       "            0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,     0.64308,\n",
       "             0.6413,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,\n",
       "               0.64,        0.64,     0.63936,     0.63854,     0.63771,     0.63692,     0.63692,     0.63692,     0.63622,      0.6355,     0.63478,     0.63406,     0.63385,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,\n",
       "            0.63077,     0.63077,     0.62961,     0.62812,     0.62769,     0.62462,     0.62462,     0.62462,     0.62462,     0.62462,     0.62462,     0.62444,     0.62323,     0.62203,     0.62094,     0.61994,     0.61893,     0.61846,     0.61846,     0.61846,     0.61846,     0.61846,     0.61846,\n",
       "            0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,\n",
       "            0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61459,     0.61278,     0.61231,     0.61231,     0.61231,     0.61231,     0.61231,     0.61231,     0.61187,     0.61119,     0.61051,     0.60983,     0.60923,     0.60923,     0.60923,     0.60897,\n",
       "            0.60764,     0.60631,     0.60569,     0.60401,         0.6,         0.6,         0.6,         0.6,         0.6,         0.6,         0.6,         0.6,     0.59938,     0.59841,     0.59744,     0.59574,     0.59385,     0.59385,     0.59385,     0.59385,     0.59385,     0.59385,     0.59385,\n",
       "            0.59385,     0.59385,     0.59385,     0.59077,     0.59077,     0.59077,     0.59077,     0.59077,     0.59077,     0.59077,     0.59077,     0.59077,     0.59024,     0.58934,     0.58843,     0.58769,     0.58769,     0.58769,     0.58769,     0.58398,     0.58154,     0.58154,     0.58154,\n",
       "            0.58154,     0.58154,     0.58154,     0.58069,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57846,     0.57835,     0.57793,\n",
       "            0.57751,     0.57708,     0.57666,     0.57624,     0.57582,      0.5754,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57538,     0.57378,     0.57231,     0.57231,     0.57169,     0.57063,\n",
       "            0.56958,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56866,     0.56769,     0.56672,     0.56584,      0.5651,     0.56436,     0.56361,     0.56299,     0.56267,     0.56236,     0.56204,     0.56173,     0.56141,      0.5611,     0.56078,\n",
       "            0.56047,     0.56015,        0.56,        0.56,     0.55966,     0.55652,     0.55538,     0.55423,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,\n",
       "            0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55332,     0.55257,     0.55183,     0.55109,     0.55029,     0.54945,     0.54861,     0.54777,     0.54769,     0.54759,     0.54709,     0.54658,     0.54608,     0.54557,     0.54507,     0.54458,\n",
       "            0.54423,     0.54388,     0.54353,     0.54318,     0.54283,     0.54248,     0.54213,     0.54177,     0.54154,     0.54154,     0.54154,     0.54154,     0.53943,     0.53499,     0.53441,     0.53384,     0.53327,     0.53269,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,\n",
       "            0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.53231,     0.52628,     0.52615,     0.52307,     0.52241,     0.52174,     0.52108,     0.52041,        0.52,        0.52,        0.52,        0.52,        0.52,        0.52,\n",
       "               0.52,        0.52,        0.52,        0.52,        0.52,     0.51978,     0.51923,     0.51868,     0.51814,     0.51759,     0.51704,     0.51385,     0.51369,      0.5135,     0.51331,     0.51312,     0.51293,     0.51273,     0.51254,     0.51235,     0.51216,     0.51197,     0.51178,\n",
       "            0.51159,      0.5114,     0.51121,     0.51101,     0.51082,      0.5102,     0.50941,     0.50863,     0.50784,     0.50769,     0.50769,     0.50769,     0.50769,     0.50769,     0.50769,     0.50697,     0.50462,     0.50374,     0.50058,     0.49824,     0.49758,     0.49692,     0.49625,\n",
       "            0.49559,     0.49231,     0.49004,     0.48576,     0.48524,     0.48471,     0.48419,     0.48366,     0.48314,     0.48027,        0.48,        0.48,        0.48,        0.48,        0.48,        0.48,        0.48,     0.47692,     0.47692,     0.47692,     0.47692,      0.4755,     0.47368,\n",
       "            0.47333,     0.47298,     0.47263,     0.47228,     0.47193,     0.47158,     0.47123,     0.47088,     0.46858,     0.46543,     0.46383,     0.46278,     0.46173,     0.46154,     0.46154,     0.46154,     0.46154,     0.46154,     0.45846,     0.45846,     0.45846,     0.45846,     0.45846,\n",
       "            0.45846,     0.45846,     0.45842,      0.4581,     0.45779,     0.45747,     0.45716,     0.45684,     0.45653,     0.45621,      0.4559,     0.45558,     0.45479,     0.45321,     0.45231,     0.45231,     0.45231,     0.45152,     0.44994,     0.44865,      0.4476,     0.44655,      0.4455,\n",
       "            0.44445,      0.4434,     0.44198,      0.4404,     0.43765,     0.43692,      0.4363,     0.43551,     0.43472,     0.43393,     0.42488,     0.42173,     0.41797,     0.41744,     0.41692,     0.41639,     0.41587,     0.41525,     0.41367,     0.41231,     0.41231,     0.41231,     0.41231,\n",
       "            0.41231,      0.4115,     0.40603,     0.40558,     0.40513,     0.40468,     0.40422,     0.40377,     0.40332,     0.40165,         0.4,         0.4,         0.4,         0.4,     0.39909,     0.39752,     0.39692,     0.39624,     0.39519,     0.39414,     0.39339,     0.39276,     0.39213,\n",
       "             0.3915,     0.39087,     0.38944,     0.38786,     0.37873,     0.37846,     0.37846,     0.37846,     0.37688,     0.37373,     0.37057,     0.36742,     0.36426,     0.36209,     0.36052,     0.35894,     0.35736,     0.35579,     0.35421,     0.35016,     0.34937,     0.34859,      0.3478,\n",
       "            0.34632,     0.34475,     0.33865,     0.33549,     0.33234,     0.33075,     0.32899,     0.32529,     0.32371,      0.3227,     0.32207,     0.32144,     0.32081,     0.32018,     0.31772,     0.31653,     0.31601,     0.31548,     0.31495,     0.31443,      0.3139,     0.30964,     0.30838,\n",
       "            0.30462,     0.30431,     0.30368,     0.30305,     0.30242,     0.30179,     0.29657,     0.29187,     0.29117,     0.29047,     0.28977,     0.28908,     0.28845,     0.28782,     0.28719,     0.28656,     0.28195,     0.27952,     0.27826,       0.277,     0.27395,     0.27283,     0.27178,\n",
       "            0.27073,     0.26983,     0.26893,     0.26803,     0.26572,     0.26257,      0.2574,     0.25582,     0.25311,     0.24871,     0.24801,     0.24731,      0.2466,     0.24503,     0.24187,     0.23915,     0.23704,     0.23692,     0.23692,     0.23692,     0.23692,     0.23679,     0.23468,\n",
       "            0.23195,      0.2288,     0.22724,     0.22654,     0.22584,     0.22513,     0.22154,     0.22154,     0.22057,     0.21776,     0.21566,     0.21264,     0.21168,     0.21098,     0.21028,     0.20958,     0.20456,      0.2026,      0.2017,      0.2008,     0.19964,     0.19663,     0.19453,\n",
       "            0.19038,     0.18981,     0.18924,     0.18866,     0.18809,     0.18704,     0.18494,     0.18195,     0.18017,     0.17859,     0.17788,     0.17725,     0.17662,     0.17599,     0.17526,     0.16902,     0.16251,     0.15937,     0.15832,     0.15726,     0.15325,     0.15032,     0.14822,\n",
       "            0.14651,     0.14493,     0.14294,     0.13793,     0.13636,     0.12682,     0.12474,     0.12317,     0.12189,     0.12062,     0.11894,     0.11376,     0.11166,     0.10986,     0.10828,      0.1073,     0.10667,     0.10604,      0.1054,     0.10477,     0.10154,     0.10128,     0.10038,\n",
       "           0.099479,    0.098578,     0.09663,    0.095127,    0.094497,    0.093866,    0.093235,    0.092604,    0.088674,    0.087622,    0.086571,    0.081809,    0.076776,    0.075725,    0.074674,     0.07351,    0.071933,    0.070769,    0.070769,     0.06993,    0.068879,    0.067827,    0.067234,\n",
       "           0.066709,    0.066183,    0.065657,    0.065132,    0.064577,    0.062475,    0.057587,     0.05601,    0.051039,    0.049083,    0.048032,    0.046981,     0.03991,     0.03949,    0.039069,    0.038649,    0.038228,    0.037808,    0.037387,    0.036967,    0.035792,    0.034531,    0.033709,\n",
       "           0.033408,    0.033108,    0.032808,    0.032507,    0.032207,    0.031906,    0.031606,    0.031306,    0.031005,    0.030673,    0.030222,    0.029772,    0.029321,    0.028871,     0.02842,     0.02797,    0.024464,    0.024069,    0.023675,    0.023281,    0.022887,    0.022492,    0.022098,\n",
       "           0.021704,    0.021206,    0.020632,    0.020059,    0.019485,    0.018912,    0.018386,    0.018036,    0.017686,    0.017335,    0.016985,    0.016634,    0.016284,    0.015933,    0.015583,    0.014472,    0.012369,    0.010267,   0.0085907,   0.0073292,   0.0061492,   0.0060806,    0.006012,\n",
       "          0.0059435,   0.0058749,   0.0058063,   0.0057378,   0.0056692,   0.0056007,   0.0055321,   0.0054635,    0.005395,   0.0053264,   0.0052578,   0.0051893,   0.0051207,   0.0050521,   0.0049836,    0.004915,   0.0048465,   0.0047779,   0.0047093,   0.0046408,   0.0045722,   0.0045036,   0.0044351,\n",
       "          0.0043665,   0.0042979,   0.0042294,   0.0041608,   0.0040923,   0.0040237,   0.0039551,   0.0038866,    0.003818,   0.0037494,   0.0036809,   0.0036123,   0.0035437,   0.0034752,   0.0034066,   0.0033381,   0.0032695,   0.0032009,   0.0031324,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.2955517324488706)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.25916])\n",
       "names: {0: 'kidney_stone'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.7608317730411582), 'metrics/recall(B)': np.float64(0.5775050948384282), 'metrics/mAP50(B)': np.float64(0.6230751694137618), 'metrics/mAP50-95(B)': np.float64(0.25916023945277156), 'fitness': np.float64(0.2955517324488706)}\n",
       "save_dir: WindowsPath('kidney-stone-yolo/yolov8s-classifier')\n",
       "speed: {'preprocess': 0.20889105685566348, 'inference': 5.081904064901779, 'loss': 0.019447154311531382, 'postprocess': 3.602740650251697}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "    data='kidney.yaml',\n",
    "    epochs=30,\n",
    "    imgsz=320,\n",
    "    batch=8,\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    project='kidney-stone-yolo',\n",
    "    name='yolov8s-classifier',\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kidney.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\model\\kidney-stone-yolo\\yolov8s-classifier\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s-classifier2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=kidney-stone-yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=kidney-stone-yolo\\yolov8s-classifier2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 20.43.8 MB/s, size: 15.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\train\\labels.cache... 1054 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1054/1054 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 16.66.6 MB/s, size: 17.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\valid\\labels.cache... 123 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to kidney-stone-yolo\\yolov8s-classifier2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mkidney-stone-yolo\\yolov8s-classifier2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.889G      1.882     0.8398     0.9815         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:19<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.712      0.547      0.575      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100     0.977G      1.977     0.9057      0.999         11        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:19<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.701      0.527       0.54        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.977G      2.048     0.9419       1.01         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:27<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.638      0.517      0.509      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.977G      2.002     0.9583      1.016         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:28<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.62      0.311      0.322       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.977G       2.01     0.9838      1.005         29        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:17<00:00,  7.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.507      0.169      0.251     0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.977G      2.052      0.981       1.01         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:18<00:00,  7.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.619       0.47       0.44      0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.977G      2.033     0.9866      1.006         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.656      0.477      0.446      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.977G      2.056     0.9558      1.029         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.675      0.535      0.517      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.977G      1.995     0.9294      1.002         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.676      0.548      0.579      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100     0.977G      2.021     0.9486      1.012          8        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.659      0.511      0.492       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.977G      2.007     0.9747       1.02         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.685       0.52      0.532      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.977G      1.959      0.918      1.001         25        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.729       0.52      0.557      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.977G      2.017     0.9018      1.001         36        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.635      0.575      0.549      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.977G      1.979     0.8702      1.009         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.636      0.538       0.52      0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.977G      1.966     0.9039      1.013         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.774      0.483      0.561      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.977G      1.935     0.8947      1.003         45        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.672      0.563      0.581      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.977G      1.989     0.9111     0.9936         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.727       0.52      0.559      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.977G       1.89     0.8476     0.9891         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.619      0.492      0.442      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100     0.977G      1.897      0.861     0.9924         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.676      0.532      0.557      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.977G      1.953     0.8783     0.9961         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.776      0.529      0.594      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100     0.977G      1.971     0.8976     0.9875         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.688      0.548      0.586       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100     0.977G      1.963     0.8834     0.9968         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.64      0.557      0.562       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100     0.977G      1.958     0.8694      0.987         41        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:23<00:00,  5.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.742      0.514      0.579      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100     0.977G      1.925     0.8756     0.9803         32        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.714      0.612       0.62      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100     0.977G      1.915      0.851     0.9911         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.655      0.545      0.539      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100     0.977G      1.863     0.8467     0.9796         10        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.722      0.563      0.584      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100     0.977G      1.898     0.8625     0.9728         27        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.718      0.554      0.566      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100     0.977G      1.913     0.8377       0.98         27        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.718        0.6      0.623      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100     0.977G      1.871     0.8398     0.9853         15        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.766      0.597      0.645       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100     0.977G      1.931     0.8642     0.9965         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.755      0.575      0.618      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100     0.977G      1.909     0.8439     0.9866         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.716      0.572        0.6      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100     0.977G      1.849     0.8191     0.9807         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.664      0.618      0.602      0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100     0.977G      1.827     0.8025     0.9848         28        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.735       0.59      0.647       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100     0.977G      1.877     0.8235     0.9549         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.717      0.569       0.58      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100     0.977G      1.834     0.8003     0.9737         14        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.729      0.578      0.601      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100     0.977G      1.865     0.8197     0.9739         16        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.765      0.591      0.617      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100     0.977G      1.843     0.8115     0.9701         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.718      0.575      0.595      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100     0.977G      1.907     0.8301     0.9779         23        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.705      0.582      0.577      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100     0.977G      1.839      0.791     0.9803          9        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.742      0.563      0.602      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100     0.977G       1.83     0.7956     0.9659         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.715      0.563      0.575      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100     0.977G      1.815     0.7842      0.976         12        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325       0.73       0.56      0.569      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100     0.977G       1.82     0.7892     0.9661         24        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.757      0.548      0.607      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100     0.977G      1.786      0.783     0.9523         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.719      0.578      0.608      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100     0.977G      1.786     0.7676     0.9498         13        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.711      0.609      0.627      0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100     0.977G      1.789     0.7786     0.9562         19        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.734      0.568      0.622      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100     0.977G      1.783     0.7728     0.9707          7        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.741      0.573      0.603      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100     0.977G      1.778     0.7659     0.9524         30        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:16<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.748      0.567      0.603      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100     0.977G       1.74     0.7643     0.9513         20        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:15<00:00,  8.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.814      0.563       0.64      0.247\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 33, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "48 epochs completed in 0.248 hours.\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8s-classifier2\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from kidney-stone-yolo\\yolov8s-classifier2\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating kidney-stone-yolo\\yolov8s-classifier2\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.12.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        325      0.709      0.572      0.634      0.262\n",
      "Speed: 0.2ms preprocess, 15.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mkidney-stone-yolo\\yolov8s-classifier2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021DD6B4CB00>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,\n",
       "            0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,\n",
       "            0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,\n",
       "            0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,\n",
       "            0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.98214,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,\n",
       "            0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,\n",
       "            0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,\n",
       "            0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,     0.97647,\n",
       "            0.97647,     0.97647,     0.97647,     0.96552,     0.96552,     0.96552,     0.95556,     0.95556,     0.95556,     0.95556,     0.95556,     0.95556,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,\n",
       "            0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,\n",
       "            0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,\n",
       "            0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.94828,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,\n",
       "            0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,\n",
       "            0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93846,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,\n",
       "            0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.93571,     0.92308,     0.92308,     0.92308,     0.91724,     0.91724,     0.91724,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,\n",
       "            0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.91447,     0.90385,     0.90385,     0.90385,     0.90385,     0.90385,     0.90385,     0.87349,     0.87349,     0.87349,\n",
       "            0.87349,     0.87349,     0.87349,     0.87349,     0.87349,     0.87349,     0.87349,     0.87349,     0.87349,     0.86982,     0.86982,     0.86982,     0.86982,     0.86982,     0.86982,     0.86628,     0.86628,     0.86628,     0.86628,     0.86628,     0.86628,     0.86628,     0.86364,\n",
       "            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,        0.85,        0.85,        0.85,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,     0.84409,\n",
       "            0.84127,     0.84127,     0.84127,     0.84127,     0.84127,     0.84127,     0.83333,     0.83333,     0.83333,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.83163,     0.82266,     0.82266,     0.82266,     0.82266,\n",
       "            0.82266,     0.82266,     0.82266,     0.82266,     0.82266,     0.82266,     0.82266,     0.82266,     0.80095,     0.80095,     0.80095,     0.80095,     0.80095,     0.80095,     0.77982,     0.77982,     0.77982,     0.77727,     0.77727,     0.77727,      0.7713,      0.7713,      0.7713,\n",
       "            0.75546,     0.75546,     0.75546,     0.75325,     0.75325,     0.75325,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,     0.74074,\n",
       "            0.74074,     0.74074,     0.73577,     0.73577,     0.73577,       0.732,       0.732,       0.732,       0.732,       0.732,       0.732,     0.72727,     0.72727,     0.72727,     0.71984,     0.71984,     0.71984,     0.71264,     0.71264,     0.71264,     0.69517,     0.69517,     0.69517,\n",
       "            0.69373,     0.69373,     0.69373,     0.68727,     0.68727,     0.68727,     0.68459,     0.68459,     0.68459,     0.68459,     0.68459,     0.68459,     0.68459,     0.67133,     0.67133,     0.67133,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.66667,     0.65878,\n",
       "            0.65878,     0.65878,     0.65347,     0.65347,     0.65347,     0.65347,     0.65347,     0.65347,     0.65347,     0.65347,     0.65347,     0.64821,     0.64821,     0.64821,     0.64309,     0.64309,     0.64309,     0.63608,     0.63608,     0.63608,     0.63522,     0.63522,     0.63522,\n",
       "            0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.62997,     0.62997,     0.62997,     0.62918,     0.62918,     0.62918,     0.62462,     0.62462,     0.62462,     0.61224,     0.61224,     0.61224,     0.61224,\n",
       "            0.61224,     0.61224,     0.59773,     0.59773,     0.59773,     0.58402,     0.58402,     0.58402,     0.57724,     0.57724,     0.57724,     0.55297,     0.55297,     0.55297,      0.5527,      0.5527,      0.5527,     0.55243,     0.55243,     0.55243,     0.54798,     0.54798,     0.54798,\n",
       "            0.54798,     0.54364,     0.54364,     0.54364,     0.50577,     0.50577,     0.50577,     0.48889,     0.48889,     0.48889,     0.48684,     0.48684,     0.48684,     0.48684,     0.48684,     0.48684,     0.48584,     0.48584,     0.48584,     0.48276,     0.48276,     0.48276,     0.46488,\n",
       "            0.46488,     0.46488,     0.40429,     0.40429,     0.40429,     0.37213,     0.37213,     0.37213,      0.3348,      0.3348,      0.3348,     0.30452,     0.30452,     0.30452,     0.28083,     0.28083,     0.28083,     0.25724,     0.25724,     0.25724,     0.25724,     0.21682,     0.21682,\n",
       "            0.21682,      0.1697,      0.1691,     0.16851,     0.16791,     0.16731,     0.16672,     0.16612,     0.16553,     0.16493,     0.16434,     0.16374,     0.16315,     0.16255,     0.16196,     0.16136,     0.16076,     0.16017,     0.15957,     0.15898,     0.15838,     0.15779,     0.15719,\n",
       "             0.1566,       0.156,     0.15541,     0.15481,     0.15422,     0.15362,     0.15302,     0.15243,     0.15183,     0.15124,     0.15064,     0.15005,     0.14945,     0.14886,     0.14826,     0.14767,     0.14707,     0.14647,     0.14588,     0.14528,     0.14469,     0.14409,      0.1435,\n",
       "             0.1429,     0.14231,     0.14171,     0.14112,     0.14052,     0.13992,     0.13933,     0.13873,     0.13814,     0.13754,     0.13695,     0.13635,     0.13576,     0.13516,     0.13457,     0.13397,     0.13338,     0.13278,     0.13218,     0.13159,     0.13099,      0.1304,      0.1298,\n",
       "            0.12921,     0.12861,     0.12802,     0.12742,     0.12683,     0.12623,     0.12563,     0.12504,     0.12444,     0.12385,     0.12325,     0.12266,     0.12206,     0.12147,     0.12087,     0.12028,     0.11968,     0.11908,     0.11849,     0.11789,      0.1173,      0.1167,     0.11611,\n",
       "            0.11551,     0.11492,     0.11432,     0.11373,     0.11313,     0.11254,     0.11194,     0.11134,     0.11075,     0.11015,     0.10956,     0.10896,     0.10837,     0.10777,     0.10718,     0.10658,     0.10599,     0.10539,     0.10479,      0.1042,      0.1036,     0.10301,     0.10241,\n",
       "            0.10182,     0.10122,     0.10063,     0.10003,    0.099436,    0.098841,    0.098245,     0.09765,    0.097054,    0.096459,    0.095863,    0.095268,    0.094673,    0.094077,    0.093482,    0.092886,    0.092291,    0.091695,      0.0911,    0.090505,    0.089909,    0.089314,    0.088718,\n",
       "           0.088123,    0.087527,    0.086932,    0.086337,    0.085741,    0.085146,     0.08455,    0.083955,    0.083359,    0.082764,    0.082169,    0.081573,    0.080978,    0.080382,    0.079787,    0.079192,    0.078596,    0.078001,    0.077405,     0.07681,    0.076214,    0.075619,    0.075024,\n",
       "           0.074428,    0.073833,    0.073237,    0.072642,    0.072046,    0.071451,    0.070856,     0.07026,    0.069665,    0.069069,    0.068474,    0.067878,    0.067283,    0.066688,    0.066092,    0.065497,    0.064901,    0.064306,     0.06371,    0.063115,     0.06252,    0.061924,    0.061329,\n",
       "           0.060733,    0.060138,    0.059542,    0.058947,    0.058352,    0.057756,    0.057161,    0.056565,     0.05597,    0.055375,    0.054779,    0.054184,    0.053588,    0.052993,    0.052397,    0.051802,    0.051207,    0.050611,    0.050016,     0.04942,    0.048825,    0.048229,    0.047634,\n",
       "           0.047039,    0.046443,    0.045848,    0.045252,    0.044657,    0.044061,    0.043466,    0.042871,    0.042275,     0.04168,    0.041084,    0.040489,    0.039893,    0.039298,    0.038703,    0.038107,    0.037512,    0.036916,    0.036321,    0.035725,     0.03513,    0.034535,    0.033939,\n",
       "           0.033344,    0.032748,    0.032153,    0.031558,    0.030962,    0.030367,    0.029771,    0.029176,     0.02858,    0.027985,     0.02739,    0.026794,    0.026199,    0.025603,    0.025008,    0.024412,    0.023817,    0.023222,    0.022626,    0.022031,    0.021435,     0.02084,    0.020244,\n",
       "           0.019649,    0.019054,    0.018458,    0.017863,    0.017267,    0.016672,    0.016076,    0.015481,    0.014886,     0.01429,    0.013695,    0.013099,    0.012504,    0.011908,    0.011313,    0.010718,    0.010122,   0.0095268,   0.0089314,   0.0083359,   0.0077405,   0.0071451,   0.0065497,\n",
       "          0.0059542,   0.0053588,   0.0047634,    0.004168,   0.0035725,   0.0029771,   0.0023817,   0.0017863,   0.0011908,  0.00059542,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.27488,     0.27488,     0.31802,     0.33869,     0.35728,      0.3761,     0.38463,     0.39446,      0.4018,     0.40686,     0.41463,     0.42146,     0.42718,     0.43364,     0.43744,     0.44423,     0.44983,     0.45335,     0.45624,     0.46188,     0.46536,     0.46977,     0.47454,\n",
       "            0.47881,     0.48182,     0.48423,     0.48719,     0.49109,     0.49268,     0.49752,     0.49811,     0.50032,     0.50399,     0.50835,     0.51034,        0.51,     0.51172,     0.51511,     0.51694,      0.5191,      0.5196,     0.52055,     0.52272,     0.52356,     0.52644,     0.53026,\n",
       "            0.53225,      0.5343,     0.53975,     0.54136,     0.54487,     0.54622,     0.54696,     0.54795,     0.54929,     0.55157,     0.55321,     0.55514,     0.55612,     0.55468,     0.55834,     0.56029,     0.56229,     0.56274,     0.56429,     0.56491,     0.56699,     0.56723,     0.56709,\n",
       "            0.56859,     0.56814,     0.56702,     0.56625,     0.56679,     0.56718,     0.56823,     0.56868,     0.57065,     0.57333,     0.57502,     0.57902,     0.57999,     0.58042,     0.58082,     0.58119,     0.58211,       0.584,     0.58501,     0.58691,     0.58741,     0.58791,     0.58842,\n",
       "            0.58932,      0.5906,     0.59263,     0.59337,      0.5957,     0.59732,     0.59826,     0.59872,     0.60007,     0.59903,     0.60067,     0.60116,     0.60013,     0.60051,     0.60176,     0.60233,     0.60268,     0.60293,     0.60317,     0.60211,     0.60171,     0.60207,     0.60094,\n",
       "            0.60067,     0.60035,     0.60182,     0.60217,     0.60252,     0.60388,     0.60453,     0.60541,     0.60638,     0.60823,     0.60945,     0.61067,       0.612,     0.61352,     0.61311,      0.6151,     0.61531,     0.61522,     0.61619,     0.61686,     0.61738,     0.61788,      0.6185,\n",
       "             0.6198,     0.62042,      0.6222,     0.62132,     0.62045,     0.62082,     0.62129,     0.62269,     0.62502,     0.62565,     0.62647,     0.62832,     0.62604,     0.62498,     0.62587,     0.62632,     0.62708,     0.62782,     0.62843,     0.63032,     0.63068,     0.63104,     0.63162,\n",
       "            0.63147,     0.63072,     0.63159,      0.6321,     0.63228,     0.63245,     0.63263,     0.63281,     0.63298,     0.63162,      0.6315,     0.63138,     0.63043,     0.62987,     0.63009,      0.6303,     0.63052,     0.63073,     0.62974,     0.62844,      0.6267,     0.62565,      0.6264,\n",
       "            0.62664,     0.62687,     0.62711,     0.62737,     0.62817,      0.6264,     0.62668,     0.62695,     0.62662,     0.62503,     0.62535,     0.62567,       0.626,     0.62681,     0.62854,     0.62882,     0.62857,     0.62832,     0.62808,     0.62783,     0.62759,     0.62734,     0.62709,\n",
       "            0.62685,     0.62778,     0.62799,     0.62821,     0.62842,     0.62863,     0.62948,      0.6282,     0.62868,     0.62889,     0.62911,     0.62933,     0.62954,     0.63021,     0.62973,     0.62776,      0.6256,     0.62454,     0.62467,     0.62621,     0.62733,     0.62582,     0.62596,\n",
       "            0.62611,     0.62625,      0.6264,     0.62655,     0.62669,     0.62684,     0.62698,     0.62712,     0.62727,     0.62741,     0.62755,      0.6277,     0.62787,     0.62857,     0.62906,      0.6294,     0.62975,     0.62953,     0.62903,     0.62852,     0.62801,     0.62743,     0.62667,\n",
       "            0.62591,     0.62565,     0.62635,     0.62705,     0.62804,      0.6272,     0.62751,     0.62778,     0.62804,     0.62832,     0.62879,     0.62926,     0.63055,     0.63197,     0.63142,     0.62803,     0.62864,     0.62966,     0.62826,     0.62919,     0.63017,     0.63079,      0.6305,\n",
       "            0.63008,     0.62965,     0.62922,     0.62879,      0.6294,     0.62892,     0.62845,     0.62797,      0.6275,     0.62821,     0.62948,     0.62974,        0.63,     0.63025,     0.63052,     0.63178,     0.63252,     0.63301,     0.63345,     0.63385,     0.63417,     0.63448,      0.6348,\n",
       "             0.6339,     0.63294,     0.63325,     0.63368,     0.63382,     0.63396,     0.63411,     0.63425,     0.63439,     0.63454,     0.63479,     0.63543,     0.63491,     0.63345,     0.63451,     0.63483,     0.63515,     0.63547,     0.63576,     0.63437,     0.63597,      0.6338,      0.6324,\n",
       "            0.63299,      0.6332,     0.63342,     0.63363,     0.63385,     0.63259,     0.63167,     0.63179,     0.63192,     0.63205,     0.63217,      0.6323,     0.63243,     0.63255,     0.63268,     0.63355,     0.63214,     0.63121,     0.63083,     0.63045,     0.63007,     0.62969,     0.62931,\n",
       "            0.62885,     0.62785,     0.62686,     0.62482,     0.62429,     0.62455,      0.6248,     0.62505,     0.62559,     0.62674,      0.6273,      0.6269,      0.6265,      0.6261,     0.62569,     0.62529,     0.62465,     0.62339,     0.62371,     0.62389,     0.62407,     0.62424,     0.62442,\n",
       "             0.6246,     0.62477,     0.62495,     0.62513,     0.62531,     0.62548,     0.62566,     0.62584,     0.62427,     0.62363,     0.62394,     0.62424,     0.62206,     0.62237,     0.62268,     0.62299,     0.62342,     0.62408,     0.62451,      0.6248,     0.62509,     0.62538,      0.6266,\n",
       "            0.62765,     0.62526,     0.62585,      0.6264,     0.62665,      0.6269,     0.62714,     0.62739,     0.62708,     0.62614,      0.6252,     0.62547,     0.62606,     0.62506,     0.62376,     0.62653,      0.6272,     0.62779,     0.62956,     0.63016,     0.62731,     0.62552,     0.62567,\n",
       "            0.62583,     0.62598,     0.62614,     0.62629,     0.62645,      0.6266,     0.62806,     0.62838,     0.62871,      0.6291,     0.63023,     0.63064,     0.63105,      0.6316,     0.63239,     0.63151,     0.63062,      0.6298,     0.62913,     0.62846,     0.62779,     0.62603,      0.6239,\n",
       "            0.62255,     0.62256,     0.62317,     0.62424,     0.62499,     0.62561,     0.62351,     0.61813,     0.61803,     0.61833,     0.61864,     0.61894,     0.61764,     0.61628,     0.61654,      0.6168,     0.61706,     0.61732,     0.61794,     0.61831,     0.61739,     0.61647,     0.61343,\n",
       "            0.61374,     0.61404,     0.61435,     0.61289,     0.61121,     0.61028,     0.60935,     0.60536,     0.60395,     0.60399,      0.6046,     0.60522,     0.60583,     0.60363,     0.60472,     0.60513,     0.60554,     0.60613,     0.60542,     0.60471,     0.60398,     0.60255,     0.60103,\n",
       "            0.59653,     0.59504,     0.59406,     0.59309,     0.58954,     0.59016,     0.59029,     0.58882,     0.58693,     0.58441,     0.58293,     0.58188,     0.58432,      0.5851,      0.5852,     0.58529,     0.58539,     0.58549,     0.58558,     0.58568,     0.58577,     0.58587,     0.58596,\n",
       "            0.58606,     0.58616,     0.58625,     0.58556,     0.58455,     0.58354,     0.58087,     0.58149,     0.58212,     0.58274,     0.58009,     0.57628,     0.57566,     0.57505,     0.57443,      0.5738,     0.57277,     0.57174,     0.57065,      0.5691,     0.56485,     0.56547,     0.56574,\n",
       "             0.5647,     0.56365,     0.56325,     0.56141,     0.56237,     0.56278,      0.5632,      0.5628,     0.56122,     0.55963,     0.55803,      0.5525,     0.54928,     0.54407,     0.54298,     0.54189,     0.53945,     0.53803,     0.53762,     0.53721,      0.5368,     0.53639,     0.53597,\n",
       "            0.53556,     0.53515,     0.53527,     0.53549,     0.53571,     0.53593,     0.53615,     0.53469,     0.53138,     0.52893,     0.52726,     0.52591,     0.52479,     0.52368,      0.5211,     0.51773,     0.51434,     0.50287,     0.50218,     0.50149,      0.5008,     0.50011,     0.49707,\n",
       "            0.49761,     0.49808,     0.49847,     0.49885,     0.49549,     0.49372,     0.49197,     0.49056,     0.48915,     0.48828,     0.48778,     0.48727,     0.48676,     0.48626,     0.48575,     0.48524,     0.48376,     0.48197,     0.48019,      0.4784,     0.47152,     0.46984,     0.46839,\n",
       "            0.46594,     0.45871,     0.45141,     0.44769,     0.44166,     0.44041,     0.43915,     0.43816,     0.43732,     0.43647,     0.43563,     0.43454,     0.43264,      0.4302,     0.42788,     0.42439,     0.42311,     0.42182,     0.41791,     0.41608,     0.41478,     0.41347,     0.41397,\n",
       "            0.41441,     0.41329,     0.41217,     0.41105,     0.41028,     0.40971,     0.40915,     0.40859,     0.40802,     0.40746,     0.40689,      0.4071,     0.40751,     0.40407,     0.40458,     0.40326,     0.39359,      0.3893,     0.38719,     0.38515,     0.38311,     0.37287,     0.36834,\n",
       "            0.35837,     0.35413,     0.34988,     0.34766,     0.34644,     0.34521,     0.34319,     0.33887,     0.33498,     0.33208,     0.32183,     0.32036,     0.31889,      0.3117,     0.30906,     0.30681,     0.30457,     0.30231,     0.28801,       0.284,     0.28169,     0.27449,     0.26544,\n",
       "            0.26229,     0.26038,     0.25902,     0.25766,     0.25064,     0.24109,     0.23458,      0.2289,     0.22611,     0.22363,     0.22039,     0.21767,     0.21567,     0.21367,     0.21224,      0.2108,     0.20936,     0.20575,     0.20315,     0.20202,     0.20089,     0.19976,     0.19342,\n",
       "            0.19137,     0.18931,     0.18724,     0.18517,     0.17824,     0.17674,     0.17525,     0.17375,     0.17169,     0.16958,     0.16676,     0.15797,     0.15286,     0.15107,     0.14927,     0.14775,     0.14793,      0.1481,     0.13562,     0.13287,     0.13081,     0.12897,     0.12713,\n",
       "            0.12452,     0.12175,     0.11815,      0.1097,     0.10782,     0.10594,    0.098632,    0.097002,    0.095369,    0.093715,    0.091803,    0.089887,    0.087967,    0.086043,    0.084116,    0.076302,     0.07338,    0.070192,    0.066269,    0.058911,     0.05792,    0.056929,    0.055936,\n",
       "           0.054942,    0.053947,    0.052009,    0.050013,    0.047976,    0.043962,    0.040491,    0.037459,    0.036075,    0.035778,    0.035481,    0.035184,    0.034887,     0.03459,    0.034293,    0.033996,    0.033698,    0.033401,    0.033103,    0.032806,    0.032508,     0.03221,    0.031912,\n",
       "           0.031614,    0.031316,    0.031018,     0.03072,    0.030421,     0.02907,    0.027026,    0.024978,    0.023273,    0.021732,    0.020188,    0.018641,    0.011542,    0.010651,   0.0097593,   0.0088666,    0.007973,   0.0070787,   0.0061835,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.17021,     0.17021,     0.20458,     0.22231,     0.23861,      0.2557,     0.26408,     0.27343,     0.28054,       0.286,     0.29374,     0.30064,     0.30709,     0.31381,      0.3178,     0.32502,     0.33105,     0.33558,     0.33876,     0.34502,     0.34891,      0.3539,     0.35934,\n",
       "            0.36426,     0.36775,     0.37129,     0.37494,     0.37958,     0.38148,     0.38731,     0.38803,     0.39072,     0.39522,      0.4006,     0.40308,     0.40369,     0.40586,     0.41014,     0.41246,     0.41521,     0.41586,     0.41708,     0.41987,     0.42095,     0.42469,     0.42969,\n",
       "             0.4323,     0.43501,     0.44229,     0.44445,     0.44921,     0.45104,     0.45205,     0.45341,     0.45525,     0.45839,     0.46065,     0.46334,      0.4647,     0.46408,     0.46923,     0.47198,     0.47484,     0.47548,      0.4777,     0.47858,     0.48157,      0.4824,     0.48324,\n",
       "            0.48566,     0.48631,     0.48624,     0.48668,     0.48909,     0.48967,     0.49124,     0.49191,     0.49487,     0.49891,     0.50148,     0.50935,     0.51085,     0.51152,     0.51213,     0.51272,     0.51416,     0.51711,     0.51869,     0.52169,     0.52248,     0.52327,     0.52407,\n",
       "            0.52551,     0.52755,      0.5308,     0.53198,     0.53574,     0.53837,     0.53989,     0.54065,     0.54286,     0.54274,     0.54588,     0.54752,     0.54705,     0.54769,     0.54976,     0.55072,      0.5513,     0.55172,     0.55213,      0.5517,      0.5518,     0.55241,     0.55193,\n",
       "            0.55221,     0.55383,     0.55635,     0.55695,     0.55754,     0.55988,       0.561,     0.56251,     0.56419,      0.5674,     0.56952,     0.57167,       0.574,     0.57706,     0.57835,      0.5819,     0.58347,     0.58459,     0.58635,     0.58757,     0.58851,     0.58942,     0.59054,\n",
       "            0.59292,     0.59406,     0.59761,     0.59712,     0.59663,      0.5974,     0.59827,     0.60087,     0.60522,     0.60642,     0.60795,     0.61201,     0.61075,     0.61017,     0.61234,     0.61321,     0.61467,     0.61609,     0.61726,     0.62093,     0.62162,     0.62232,     0.62346,\n",
       "            0.62422,     0.62464,     0.62634,     0.62735,      0.6277,     0.62805,     0.62839,     0.62874,     0.62909,     0.62842,     0.62917,     0.62969,     0.62917,     0.62898,     0.62941,     0.62984,     0.63027,      0.6307,     0.63021,     0.62951,     0.62857,     0.62982,     0.63135,\n",
       "            0.63182,      0.6323,     0.63278,     0.63332,     0.63495,     0.63454,     0.63511,     0.63568,     0.63579,     0.63497,     0.63564,      0.6363,     0.63699,     0.63866,     0.64227,     0.64303,     0.64289,     0.64276,     0.64263,      0.6425,     0.64237,     0.64224,     0.64211,\n",
       "            0.64198,     0.64405,      0.6445,     0.64495,      0.6454,     0.64585,     0.64764,     0.64838,     0.64941,     0.64987,     0.65033,     0.65079,     0.65125,     0.65269,     0.65302,     0.65198,     0.65085,     0.65028,     0.65147,     0.65482,     0.65842,     0.65765,     0.65797,\n",
       "             0.6583,     0.65862,     0.65894,     0.65926,     0.65958,      0.6599,     0.66022,     0.66054,     0.66086,     0.66118,      0.6615,     0.66182,      0.6622,     0.66375,     0.66484,     0.66562,      0.6664,     0.66649,     0.66623,     0.66597,     0.66571,     0.66541,     0.66501,\n",
       "            0.66462,     0.66491,     0.66648,     0.66807,     0.67034,      0.6724,     0.67312,     0.67373,     0.67434,     0.67497,     0.67606,     0.67715,     0.68014,     0.68347,     0.68407,      0.6826,     0.68405,     0.68647,     0.68744,     0.68968,     0.69202,     0.69352,     0.69355,\n",
       "            0.69333,     0.69312,     0.69291,      0.6927,     0.69505,     0.69482,     0.69459,     0.69435,     0.69412,     0.69622,     0.69935,     0.69998,     0.70062,     0.70125,     0.70191,     0.70505,     0.70688,     0.70812,     0.70923,     0.71022,     0.71102,     0.71181,     0.71261,\n",
       "            0.71221,     0.71176,     0.71349,     0.71457,     0.71494,     0.71531,     0.71567,     0.71604,     0.71641,     0.71677,     0.71743,     0.71906,     0.71946,     0.71891,     0.72164,     0.72247,      0.7233,     0.72413,     0.72685,     0.72622,     0.73175,     0.73076,     0.73013,\n",
       "            0.73311,     0.73369,     0.73427,     0.73485,     0.73544,     0.73515,     0.73493,     0.73527,     0.73562,     0.73596,      0.7363,     0.73665,     0.73699,     0.73733,     0.73767,     0.74063,        0.74,     0.73959,     0.73942,     0.73925,     0.73908,     0.73891,     0.73874,\n",
       "            0.73853,     0.73808,     0.73764,     0.73672,     0.73691,     0.73761,     0.73832,     0.73902,     0.74054,     0.74375,      0.7457,     0.74552,     0.74534,     0.74516,     0.74499,     0.74481,     0.74453,     0.74397,     0.74695,     0.74745,     0.74796,     0.74847,     0.74898,\n",
       "            0.74948,     0.74999,      0.7505,     0.75102,     0.75153,     0.75204,     0.75255,     0.75306,     0.75254,     0.75277,     0.75367,     0.75457,     0.75439,      0.7553,     0.75621,     0.75712,      0.7584,     0.76036,     0.76162,     0.76249,     0.76335,     0.76422,     0.76789,\n",
       "            0.77126,     0.77037,     0.77216,     0.77384,      0.7746,     0.77535,     0.77611,     0.77687,     0.77709,     0.77671,     0.77634,      0.7777,     0.77952,     0.77938,     0.77886,     0.78796,     0.79006,     0.79196,     0.79761,     0.79955,     0.79973,      0.7992,      0.7997,\n",
       "            0.80021,     0.80072,     0.80123,     0.80174,     0.80225,     0.80275,     0.80756,     0.80863,      0.8097,     0.81102,     0.81478,     0.81615,     0.81751,     0.81938,      0.8226,      0.8223,       0.822,     0.82172,     0.82149,     0.82126,     0.82104,     0.82043,      0.8197,\n",
       "            0.81924,     0.82057,     0.82269,     0.82641,     0.82907,     0.83123,     0.83091,     0.82914,     0.82997,     0.83108,     0.83219,     0.83329,      0.8329,     0.83247,     0.83342,     0.83436,     0.83531,     0.83625,     0.83855,     0.84115,     0.84087,     0.84058,     0.84012,\n",
       "            0.84128,     0.84243,     0.84359,     0.84359,     0.84307,     0.84278,     0.84249,     0.84123,     0.84078,     0.84237,     0.84475,     0.84715,     0.84956,      0.8493,     0.85532,     0.85697,     0.85862,     0.86345,     0.86325,     0.86305,     0.86285,     0.86245,     0.86202,\n",
       "            0.86543,     0.86979,     0.86953,     0.86926,     0.86875,     0.87143,      0.8734,     0.87301,      0.8725,     0.87183,     0.87143,     0.88326,     0.89461,     0.89827,     0.89873,     0.89918,     0.89963,     0.90009,     0.90054,       0.901,     0.90145,      0.9019,     0.90236,\n",
       "            0.90281,     0.90327,     0.90372,     0.90369,     0.90348,     0.90327,     0.90499,     0.90802,     0.91108,     0.91414,     0.91396,     0.91322,      0.9131,     0.91299,     0.91287,     0.91274,     0.91254,     0.91234,     0.91213,     0.91182,     0.91147,     0.91469,      0.9172,\n",
       "              0.917,     0.91681,     0.91851,     0.92459,     0.92983,     0.93209,     0.93436,     0.93562,     0.93538,     0.93514,      0.9349,     0.93406,     0.93356,     0.93274,     0.93257,      0.9324,       0.932,     0.93178,     0.93171,     0.93164,     0.93157,     0.93151,     0.93144,\n",
       "            0.93137,     0.93131,     0.93242,     0.93376,     0.93509,     0.93643,     0.93776,     0.93823,     0.93774,     0.93737,     0.93712,     0.93691,     0.93674,     0.93657,     0.93617,     0.93564,     0.93511,     0.93325,     0.93314,     0.93302,     0.93291,     0.93279,     0.93228,\n",
       "            0.93929,     0.94264,     0.94541,     0.94818,     0.94783,     0.94759,     0.94736,     0.94717,     0.94698,     0.94686,     0.94679,     0.94672,     0.94665,     0.94658,     0.94651,     0.94644,     0.94624,     0.94599,     0.94574,     0.94549,      0.9445,     0.94425,     0.94404,\n",
       "            0.94368,     0.94259,     0.94145,     0.94086,     0.93989,     0.93968,     0.93947,     0.93931,     0.93917,     0.93902,     0.93888,      0.9387,     0.93838,     0.93796,     0.94061,     0.94674,     0.94655,     0.94635,     0.94575,     0.94546,     0.94526,     0.94506,     0.95039,\n",
       "            0.95555,      0.9554,     0.95526,     0.95511,     0.95501,     0.95493,     0.95486,     0.95479,     0.95471,     0.95464,     0.95456,     0.95813,     0.96262,     0.96719,     0.97301,     0.97635,     0.97564,     0.97532,     0.97516,       0.975,     0.97484,       0.974,     0.97362,\n",
       "            0.97274,     0.97236,     0.97196,     0.97175,     0.97163,     0.97152,     0.97132,     0.97089,      0.9705,      0.9702,     0.96909,     0.96893,     0.96876,     0.96793,     0.96762,     0.96735,     0.96707,     0.96679,     0.96606,      0.9818,     0.98163,     0.98108,     0.98035,\n",
       "            0.98008,     0.97992,      0.9798,     0.97968,     0.97904,     0.97811,     0.97743,     0.97681,      0.9765,     0.97621,     0.97583,      0.9755,     0.97525,       0.975,     0.97481,     0.97462,     0.97443,     0.97394,     0.97358,     0.97342,     0.97326,      0.9731,     0.97215,\n",
       "            0.97182,     0.97149,     0.97115,     0.97081,      0.9696,     0.96932,     0.96904,     0.96877,     0.96836,     0.96795,     0.96737,     0.96546,     0.96426,      0.9638,     0.96335,     0.96508,     0.98026,     0.99545,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.71385,     0.71385,     0.71385,     0.71077,     0.71077,     0.71077,     0.70769,     0.70769,     0.70769,     0.70462,     0.70462,     0.70462,     0.70154,     0.70154,     0.70154,     0.70154,     0.70154,     0.69846,     0.69846,     0.69846,     0.69846,     0.69846,     0.69846,\n",
       "            0.69846,     0.69846,     0.69594,     0.69538,     0.69538,     0.69538,     0.69538,     0.69538,     0.69538,     0.69538,     0.69538,     0.69538,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,\n",
       "            0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.69231,     0.68923,     0.68923,     0.68923,     0.68923,     0.68923,     0.68923,     0.68923,     0.68923,     0.68825,     0.68615,\n",
       "            0.68567,     0.68308,        0.68,     0.67692,     0.67385,     0.67385,     0.67385,     0.67385,     0.67385,     0.67385,     0.67385,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,\n",
       "            0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.67077,     0.66835,     0.66769,     0.66645,     0.66462,     0.66462,     0.66462,     0.66462,     0.66462,     0.66462,     0.66462,     0.66266,     0.66154,     0.66154,     0.65949,\n",
       "            0.65846,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,     0.65538,      0.6549,     0.65231,     0.65231,     0.65083,     0.64923,     0.64923,     0.64923,     0.64923,     0.64923,     0.64923,\n",
       "            0.64923,     0.64923,      0.6489,     0.64757,     0.64625,     0.64615,     0.64615,     0.64615,     0.64615,     0.64615,     0.64615,     0.64552,     0.64211,     0.64053,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,        0.64,\n",
       "            0.63889,     0.63692,     0.63692,     0.63692,     0.63692,     0.63692,     0.63692,     0.63692,     0.63692,     0.63486,     0.63385,     0.63309,     0.63169,     0.63077,     0.63077,     0.63077,     0.63077,     0.63077,     0.62927,     0.62737,     0.62485,     0.62154,     0.62154,\n",
       "            0.62154,     0.62154,     0.62154,     0.62154,     0.62154,     0.61846,     0.61846,     0.61846,     0.61771,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61538,     0.61522,     0.61487,     0.61452,     0.61417,     0.61382,     0.61347,     0.61312,     0.61277,\n",
       "            0.61242,     0.61231,     0.61231,     0.61231,     0.61231,     0.61231,     0.61231,     0.60923,     0.60923,     0.60923,     0.60923,     0.60923,     0.60923,     0.60923,     0.60804,     0.60526,     0.60224,     0.60075,         0.6,         0.6,     0.59904,     0.59692,     0.59692,\n",
       "            0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59692,     0.59646,     0.59576,     0.59506,     0.59435,     0.59356,     0.59251,\n",
       "            0.59146,     0.59077,     0.59077,     0.59077,     0.59077,     0.58769,     0.58769,     0.58769,     0.58769,     0.58769,     0.58769,     0.58769,     0.58769,     0.58769,     0.58629,     0.58154,     0.58154,     0.58154,     0.57846,     0.57846,     0.57846,     0.57846,     0.57797,\n",
       "            0.57739,     0.57682,     0.57625,     0.57567,     0.57507,     0.57444,     0.57381,     0.57318,     0.57255,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,     0.57231,\n",
       "             0.5711,     0.56984,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56923,     0.56814,     0.56615,     0.56615,     0.56615,     0.56615,     0.56615,     0.56495,     0.56315,     0.56236,     0.55955,     0.55774,\n",
       "            0.55692,     0.55692,     0.55692,     0.55692,     0.55692,     0.55515,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55385,     0.55352,     0.55172,     0.55054,     0.55006,     0.54957,     0.54908,      0.5486,     0.54811,\n",
       "            0.54753,     0.54627,       0.545,     0.54243,     0.54154,     0.54154,     0.54154,     0.54154,     0.54154,     0.54154,     0.54135,     0.54084,     0.54034,     0.53984,     0.53933,     0.53883,     0.53802,     0.53645,     0.53538,     0.53538,     0.53538,     0.53538,     0.53538,\n",
       "            0.53538,     0.53538,     0.53538,     0.53538,     0.53538,     0.53538,     0.53538,     0.53538,     0.53336,     0.53231,     0.53231,     0.53231,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,     0.52923,\n",
       "            0.52912,     0.52615,     0.52615,     0.52615,     0.52615,     0.52615,     0.52615,     0.52615,     0.52561,     0.52446,     0.52332,     0.52308,     0.52308,     0.52175,     0.52018,        0.52,        0.52,        0.52,        0.52,        0.52,     0.51605,     0.51385,     0.51385,\n",
       "            0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51385,     0.51363,     0.51258,     0.51153,     0.51055,     0.50976,     0.50897,     0.50818,     0.50611,      0.5036,\n",
       "            0.50202,     0.50154,     0.50154,     0.50154,     0.50154,     0.50154,     0.49897,     0.49274,     0.49231,     0.49231,     0.49231,     0.49231,     0.49079,     0.48923,     0.48923,     0.48923,     0.48923,     0.48923,     0.48923,     0.48881,     0.48776,     0.48671,     0.48308,\n",
       "            0.48308,     0.48308,     0.48308,     0.48127,     0.47937,     0.47832,     0.47727,     0.47279,     0.47121,     0.47077,     0.47077,     0.47077,     0.47077,     0.46819,     0.46769,     0.46769,     0.46769,     0.46697,     0.46618,     0.46539,      0.4646,     0.46302,     0.46135,\n",
       "            0.45512,     0.45219,     0.45114,     0.45009,     0.44615,     0.44615,     0.44579,     0.44421,     0.44219,     0.43952,     0.43794,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,     0.43385,\n",
       "            0.43385,     0.43385,     0.43385,     0.43309,     0.43204,     0.43099,     0.42769,     0.42769,     0.42769,     0.42769,     0.42488,     0.42096,     0.42033,      0.4197,     0.41907,     0.41842,     0.41737,     0.41632,     0.41521,     0.41363,     0.40923,     0.40923,     0.40901,\n",
       "            0.40796,     0.40691,     0.40615,     0.40308,     0.40308,     0.40308,     0.40308,     0.40244,     0.40086,     0.39929,     0.39771,     0.39227,     0.38911,     0.38404,     0.38299,     0.38193,     0.37957,     0.37821,     0.37781,     0.37742,     0.37702,     0.37663,     0.37624,\n",
       "            0.37584,     0.37545,     0.37538,     0.37538,     0.37538,     0.37538,     0.37538,     0.37388,     0.37073,      0.3684,     0.36682,     0.36555,      0.3645,     0.36345,     0.36103,     0.35788,     0.35473,     0.34416,     0.34353,      0.3429,     0.34227,     0.34164,     0.33888,\n",
       "            0.33846,     0.33846,     0.33846,     0.33846,     0.33542,     0.33382,     0.33226,       0.331,     0.32974,     0.32896,     0.32851,     0.32806,     0.32761,     0.32716,     0.32671,     0.32626,     0.32494,     0.32336,     0.32178,     0.32021,     0.31418,     0.31272,     0.31146,\n",
       "            0.30934,     0.30311,     0.29688,     0.29372,     0.28865,      0.2876,     0.28655,     0.28572,     0.28502,     0.28431,     0.28361,     0.28271,     0.28113,     0.27911,     0.27692,      0.2735,     0.27245,     0.27139,     0.26821,     0.26673,     0.26568,     0.26463,     0.26462,\n",
       "            0.26458,     0.26368,     0.26278,     0.26188,     0.26126,     0.26081,     0.26036,     0.25991,     0.25945,       0.259,     0.25855,     0.25846,     0.25846,     0.25538,     0.25538,      0.2541,     0.24652,     0.24318,     0.24155,     0.23998,      0.2384,     0.23057,     0.22713,\n",
       "            0.21964,     0.21649,     0.21333,      0.2117,      0.2108,      0.2099,     0.20841,     0.20526,     0.20243,     0.20033,     0.19296,     0.19191,     0.19085,     0.18576,      0.1839,     0.18232,     0.18074,     0.17917,     0.16923,     0.16601,     0.16444,     0.15956,      0.1535,\n",
       "             0.1514,     0.15014,     0.14924,     0.14834,     0.14372,     0.13749,     0.13328,     0.12964,     0.12786,     0.12628,     0.12422,      0.1225,     0.12124,     0.11999,     0.11908,     0.11818,     0.11728,     0.11502,     0.11341,     0.11271,     0.11201,      0.1113,     0.10739,\n",
       "            0.10613,     0.10487,     0.10361,     0.10235,    0.098139,    0.097237,    0.096336,    0.095435,    0.094194,    0.092932,    0.091246,    0.086023,    0.083008,    0.081956,    0.080905,        0.08,        0.08,        0.08,    0.072742,    0.071165,    0.069982,     0.06893,    0.067879,\n",
       "           0.066396,    0.064819,    0.062784,    0.058033,    0.056982,     0.05593,    0.051874,    0.050973,    0.050072,    0.049161,     0.04811,    0.047058,    0.046007,    0.044956,    0.043904,    0.039664,    0.038087,    0.036373,     0.03427,     0.03035,    0.029824,    0.029298,    0.028773,\n",
       "           0.028247,    0.027721,    0.026699,    0.025648,    0.024577,    0.022475,    0.020664,    0.019087,    0.018369,    0.018215,    0.018061,    0.017907,    0.017753,    0.017599,    0.017446,    0.017292,    0.017138,    0.016984,     0.01683,    0.016676,    0.016522,    0.016369,    0.016215,\n",
       "           0.016061,    0.015907,    0.015753,    0.015599,    0.015446,     0.01475,    0.013698,    0.012647,    0.011774,    0.010985,    0.010197,   0.0094083,   0.0058047,   0.0053541,   0.0049036,    0.004453,   0.0040025,   0.0035519,   0.0031013,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.2992214006102297)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.26197])\n",
       "names: {0: 'kidney_stone'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.709229782419345), 'metrics/recall(B)': np.float64(0.5723076923076923), 'metrics/mAP50(B)': np.float64(0.6344751507160553), 'metrics/mAP50-95(B)': np.float64(0.2619709839318046), 'fitness': np.float64(0.2992214006102297)}\n",
       "save_dir: WindowsPath('kidney-stone-yolo/yolov8s-classifier2')\n",
       "speed: {'preprocess': 0.16624715481600838, 'inference': 15.26053577230399, 'loss': 0.0004821137063265816, 'postprocess': 1.8475837399804496}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\model\\kidney-stone-yolo\\yolov8s-classifier\\weights\\best.pt') \n",
    "model.train(\n",
    "    data='kidney.yaml',\n",
    "    imgsz=320,\n",
    "    batch=8,\n",
    "    epochs=100,\n",
    "    patience=15,\n",
    "    augment=True,\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    project='kidney-stone-yolo',\n",
    "    name='yolov8s-classifier',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63703718086120120200001-5487554579919763006_png_jpg.rf.9fd67251e99a47dbe83a5db6efe6c016.jpg: 288x320 1 kidney_stone, 70.0ms\n",
      "image 2/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705534438365105500001-5275982036206127404_png_jpg.rf.365c4daf2b772012fe47e07b9daec86e.jpg: 288x320 2 kidney_stones, 37.9ms\n",
      "image 3/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705540012666937300001-5673688970564737961_png_jpg.rf.15cca2fecc5f56865de3eb405476b90d.jpg: 288x320 1 kidney_stone, 9.4ms\n",
      "image 4/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705542123217653900001-5305208767418446842_png_jpg.rf.d6f32a0ac819e4f2a870edfc1ce8079b.jpg: 288x320 2 kidney_stones, 26.0ms\n",
      "image 5/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63705542123253656000001-4874858110489948158_png_jpg.rf.d79767eb8378783858ea648a8852c859.jpg: 288x320 1 kidney_stone, 36.0ms\n",
      "image 6/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63706052409136049800001-4885266517035478638_png_jpg.rf.403057fc6d27ba2b8a1020faf23ea6e8.jpg: 288x320 2 kidney_stones, 16.5ms\n",
      "image 7/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63708127596145343100001-4627297054586587945_png_jpg.rf.08b0ce91b3f33c2e333fa6b6a1fd3b19.jpg: 288x320 2 kidney_stones, 42.5ms\n",
      "image 8/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63709079072689291800001-4862263206834957747_png_jpg.rf.cd218d4ed600ad3b24e4af71077096bd.jpg: 288x320 1 kidney_stone, 21.8ms\n",
      "image 9/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63709084528362338400001-4912820873516884035_png_jpg.rf.f90314744947b62d675720abfbabe788.jpg: 288x320 1 kidney_stone, 20.3ms\n",
      "image 10/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711136318804220000001-5037705534676835423_png_jpg.rf.7548934bf8faa3895e23ab4416f079f2.jpg: 288x320 2 kidney_stones, 10.6ms\n",
      "image 11/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711492298767054500001-4654753270740370732_png_jpg.rf.9c862fae8e8b3d20eaea4dfbc977e94c.jpg: 288x320 6 kidney_stones, 25.1ms\n",
      "image 12/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63711748853420141600001-4956861441945142931_png_jpg.rf.17718d33d3b046338870e2b5048ae1c4.jpg: 288x320 2 kidney_stones, 14.5ms\n",
      "image 13/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712177173773843700001-5180703495942929996_png_jpg.rf.e93c041d68b6e726524f2d1344c079e8.jpg: 288x320 1 kidney_stone, 18.0ms\n",
      "image 14/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712258135176571000001-4759577505848141624_png_jpg.rf.b91c88cd8bbc6074f8163a75d9c28d3b.jpg: 288x320 1 kidney_stone, 22.2ms\n",
      "image 15/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63712447732648726100001-5688637637398265537_png_jpg.rf.662c088ba8390b2f998e83343f885879.jpg: 288x320 6 kidney_stones, 28.8ms\n",
      "image 16/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63713387527442829100001-4953850576413253802_png_jpg.rf.3c687e765595c73826990914236c246c.jpg: 288x320 1 kidney_stone, 44.6ms\n",
      "image 17/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714693213822369100001-5303423760460200335_png_jpg.rf.129f870203e2dd30226016194e3eefc0.jpg: 288x320 1 kidney_stone, 20.7ms\n",
      "image 18/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714778964016519000001-5315246250911861092_png_jpg.rf.7b9331ca2327df596e44e33250f8d3a5.jpg: 288x320 2 kidney_stones, 13.5ms\n",
      "image 19/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63714785261606720600001-5297890145649776819_png_jpg.rf.b1d6426b485945c55414dc7f3a4f036f.jpg: 288x320 1 kidney_stone, 18.3ms\n",
      "image 20/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715282588651483300001-4633048094895900863_png_jpg.rf.4d767c1e9e382ff304d03230490bbf48.jpg: 288x320 1 kidney_stone, 23.1ms\n",
      "image 21/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715282588697485900001-4980671363637353986_png_jpg.rf.942e6d1d8c91713ebd262b0d50ebc83b.jpg: 288x320 (no detections), 25.2ms\n",
      "image 22/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63715478193571367600001-5500741759278123745_png_jpg.rf.85bf8f585d53d6b1abf90e74571f652a.jpg: 288x320 3 kidney_stones, 34.8ms\n",
      "image 23/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716060912810080600001-5177371803856412349_png_jpg.rf.66595d72566632ecf83c25a66fbf0517.jpg: 288x320 1 kidney_stone, 12.4ms\n",
      "image 24/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716409318594992900001-4855160927526165509_png_jpg.rf.a9ef656189801fc51d430c16cdc0cfe6.jpg: 288x320 4 kidney_stones, 10.9ms\n",
      "image 25/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716412431841060400001-5514887833163602186_png_jpg.rf.09b76879c6e61bf3e8de9ee6669c6654.jpg: 288x320 1 kidney_stone, 15.3ms\n",
      "image 26/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716498031721668100001-4956700971682825541_png_jpg.rf.29537235066c7c0880560e2ddf9b706c.jpg: 288x320 1 kidney_stone, 9.9ms\n",
      "image 27/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716499019405160400001-5458996708150830273_png_jpg.rf.ab62109cadfa41271f627c4b6d33bdf5.jpg: 288x320 (no detections), 10.8ms\n",
      "image 28/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63716506118862226100001-5296184705475439164_png_jpg.rf.df5142263bbbd253f72ffd9093361538.jpg: 288x320 1 kidney_stone, 18.3ms\n",
      "image 29/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717093170609543600001-5475900208815646711_png_jpg.rf.c3b65a7eee4814452137303241df0602.jpg: 288x320 1 kidney_stone, 11.4ms\n",
      "image 30/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717702095752440600001-4849669955451581367_png_jpg.rf.60bea159c3babe4188e6a7e7af9c1d83.jpg: 288x320 1 kidney_stone, 13.5ms\n",
      "image 31/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63717795419239238700001-5010543312669228864_png_jpg.rf.a5329a41a44e18f916c7e0d2ccdba442.jpg: 288x320 1 kidney_stone, 8.8ms\n",
      "image 32/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63718233702530473000001-4932089458327885764_png_jpg.rf.5d056a9fa419a38b3cf013c5a4acd9d6.jpg: 288x320 (no detections), 12.5ms\n",
      "image 33/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63718396246548937900001-4979904738055316795_png_jpg.rf.a8c37077a88165c7440a9174f4e7de43.jpg: 288x320 1 kidney_stone, 10.6ms\n",
      "image 34/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63720209448267540500001-4892102259156693508_png_jpg.rf.cae7de5a8012ca6a47e1a58e5cf754ac.jpg: 288x320 1 kidney_stone, 15.2ms\n",
      "image 35/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63724359033331543500001-4872003896315347521_png_jpg.rf.f6eea33aaf948523c2f84729b25a9e12.jpg: 288x320 1 kidney_stone, 9.5ms\n",
      "image 36/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63724531796428573400001-5583374326157765524_png_jpg.rf.6daa696645b8939906b76ec6a356485a.jpg: 288x320 2 kidney_stones, 14.3ms\n",
      "image 37/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63726947282502574300001-4970319928017941413_png_jpg.rf.99af32963cd119463adc99e97594a21f.jpg: 288x320 2 kidney_stones, 11.0ms\n",
      "image 38/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63728083381661697400001-4679487026905507827_png_jpg.rf.5428fa1c2bbdb04a07cefeb9fdb0245a.jpg: 288x320 1 kidney_stone, 14.5ms\n",
      "image 39/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63733253864938749700001-4681200788163641056_png_jpg.rf.66ab082ae6de546b5dcec3741a10002d.jpg: 288x320 1 kidney_stone, 21.8ms\n",
      "image 40/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63733253865035755300001-4735710385933343151_png_jpg.rf.5125f3d832afdccaeacd077570d1c518.jpg: 288x320 1 kidney_stone, 13.0ms\n",
      "image 41/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735369110917000400001-4789011592236734083_png_jpg.rf.5d1c4e7ed45b6ee6fdc806d0ba1eb045.jpg: 288x320 1 kidney_stone, 13.1ms\n",
      "image 42/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735427803624058800001-4771913503464895901_png_jpg.rf.4689997f30a6d2dbf94a8d3b3fb49bf4.jpg: 288x320 1 kidney_stone, 16.9ms\n",
      "image 43/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63735865531690592300001-4898255826670355350_png_jpg.rf.1d51373e4d5a21447682d9c3188b17ea.jpg: 288x320 (no detections), 11.6ms\n",
      "image 44/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63736458322797005700001-5208768444025627150_png_jpg.rf.c33a6719d4a112109220c81c365ecf92.jpg: 288x320 (no detections), 11.0ms\n",
      "image 45/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63736458322910012200001-5596777648389044571_png_jpg.rf.aa4bff6d522d54f8f2cba68374934eb7.jpg: 288x320 1 kidney_stone, 13.1ms\n",
      "image 46/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63737665951722101900001-4980416796139912950_png_jpg.rf.f353747c7833c71191e7c00c1e8766c2.jpg: 288x320 2 kidney_stones, 15.0ms\n",
      "image 47/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63737761963388615900001-5365329265867089579_png_jpg.rf.f25ba6213cde91356bf1c9dcef015536.jpg: 288x320 1 kidney_stone, 24.0ms\n",
      "image 48/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738098194063336000001-5663074065567912123_png_jpg.rf.37b1dd022a096b834165ee6d6934f231.jpg: 288x320 1 kidney_stone, 9.6ms\n",
      "image 49/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833351756200001-5564599162858324788_png_jpg.rf.43472de584051c332b482d37ffdbae81.jpg: 288x320 1 kidney_stone, 11.4ms\n",
      "image 50/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833519765800001-5338777203487041753_png_jpg.rf.ffb224a50276c7fd005a9a63b11c03d7.jpg: 288x320 (no detections), 15.6ms\n",
      "image 51/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738185833691775600001-5590086017766645144_png_jpg.rf.0a7f335f79875c15042c8609acefc081.jpg: 288x320 1 kidney_stone, 17.7ms\n",
      "image 52/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738190974140792500001-4720089151456993587_png_jpg.rf.11473b32d8db11ef403f696b4344c4a9.jpg: 288x320 2 kidney_stones, 14.0ms\n",
      "image 53/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738356146609408000001-5713964260076015331_png_jpg.rf.2a3c2b59fbaf56a193d9f14dbb932dbb.jpg: 288x320 1 kidney_stone, 17.5ms\n",
      "image 54/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738356146648410200001-5599996945315430757_png_jpg.rf.be14f39eedc9a8124d7548385adc2e9e.jpg: 288x320 1 kidney_stone, 15.2ms\n",
      "image 55/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738370133490411800001-5404980644211618423_png_jpg.rf.3a09d97eaf51aa1d631864d196be4c8e.jpg: 288x320 1 kidney_stone, 30.2ms\n",
      "image 56/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770518044400001-5249604505762831012_png_jpg.rf.f5fe8e3e350ad44695b18fdad5deecfa.jpg: 288x320 4 kidney_stones, 22.5ms\n",
      "image 57/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770596048900001-4824455686483061274_png_jpg.rf.6188a819e2fb98eea23efbb9be751e79.jpg: 288x320 3 kidney_stones, 14.5ms\n",
      "image 58/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770632051000001-5568393716624394208_png_jpg.rf.628a9ca8339eddd0fcfd4251406c2f2f.jpg: 288x320 2 kidney_stones, 14.9ms\n",
      "image 59/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738371770669053100001-5253894092784862820_png_jpg.rf.755195eaaea732718c44d5ae55f48038.jpg: 288x320 1 kidney_stone, 9.3ms\n",
      "image 60/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738372833265830100001-5268315040608780318_png_jpg.rf.a324465bc4148dd83006ed15e0014ab4.jpg: 288x320 1 kidney_stone, 13.5ms\n",
      "image 61/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738372833373836300001-5519774372911833463_png_jpg.rf.188351529ff79195cc4a7f85e5249dae.jpg: 288x320 1 kidney_stone, 11.4ms\n",
      "image 62/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345321539100001-5134515060150907763_png_jpg.rf.23d5086bb0af16ec18561b0747bba45e.jpg: 288x320 2 kidney_stones, 17.3ms\n",
      "image 63/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345351540800001-4833200762892797527_png_jpg.rf.85a9e70dc89f0c6fb76804c9b99586bd.jpg: 288x320 1 kidney_stone, 11.3ms\n",
      "image 64/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345419544700001-4764726950619361819_png_jpg.rf.97419e3eca99cb7413678fb1a7b743b2.jpg: 288x320 2 kidney_stones, 10.9ms\n",
      "image 65/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738698345487548600001-5200702102842530817_png_jpg.rf.e0f4ffa8f9621e429e264cedb1d6cf11.jpg: 288x320 1 kidney_stone, 9.7ms\n",
      "image 66/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738701495856739400001-5065202867097533816_png_jpg.rf.ced9aca5815aff9c5ed0bfc426d07fa9.jpg: 288x320 1 kidney_stone, 12.4ms\n",
      "image 67/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738712076510918200001-4807005421736379114_png_jpg.rf.41d63d9c3438d6c9f04d09958d992e3e.jpg: 288x320 1 kidney_stone, 19.6ms\n",
      "image 68/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738712076544920100001-5262560504645227519_png_jpg.rf.2256c712e5298fb1d068b9b5bd6b260f.jpg: 288x320 1 kidney_stone, 12.7ms\n",
      "image 69/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738790795811795900001-5522258459602207098_png_jpg.rf.eb9d2068c9f992781bb9814fb156c9e4.jpg: 288x320 1 kidney_stone, 9.0ms\n",
      "image 70/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738802300674836400001-5327638065247668022_png_jpg.rf.b2af98a9baeee013c0b25338cd109873.jpg: 288x320 1 kidney_stone, 7.9ms\n",
      "image 71/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738957179044522400001-5409943715000019799_png_jpg.rf.2e53c9353b5d8b198b1ce0c679baad07.jpg: 288x320 1 kidney_stone, 10.3ms\n",
      "image 72/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738957179074524100001-5408839826702883633_png_jpg.rf.22cd2cfe17608bd6192184e5427f4543.jpg: 288x320 1 kidney_stone, 9.0ms\n",
      "image 73/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63738962850935936000001-5585661387672826890_png_jpg.rf.84352e7d4390c45cf35e145194a23c63.jpg: 288x320 3 kidney_stones, 12.8ms\n",
      "image 74/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739062195410379400001-5653448602067015935_png_jpg.rf.98c0439158bf00599778b20933ad1ff9.jpg: 288x320 1 kidney_stone, 14.4ms\n",
      "image 75/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739062195468382700001-5218664360642519214_png_jpg.rf.010f0c3970dd5d410cff3733975dab0d.jpg: 288x320 1 kidney_stone, 12.4ms\n",
      "image 76/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739323961675419500001-4924993173499860596_png_jpg.rf.a0469746d691b54882df3b6bab1f572d.jpg: 288x320 1 kidney_stone, 9.8ms\n",
      "image 77/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739323961724422300001-4739168711678747511_png_jpg.rf.dbeb5256691c7fb946003ceac0fa6a08.jpg: 288x320 1 kidney_stone, 9.2ms\n",
      "image 78/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739391821497779300001-5433422355666233277_png_jpg.rf.4ee428144959e7af6db2cff013886aab.jpg: 288x320 3 kidney_stones, 7.8ms\n",
      "image 79/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739391821525780900001-5108486655690178522_png_jpg.rf.4caf1c26455d6118d2aa8af9d7e3aa75.jpg: 288x320 3 kidney_stones, 9.7ms\n",
      "image 80/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739476574564149600001-5439781160937608718_png_jpg.rf.9d41594a6d586bb6256b8b0ecf14c37a.jpg: 288x320 1 kidney_stone, 10.0ms\n",
      "image 81/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63739476574598151500001-4717916049937277621_png_jpg.rf.bdaff9165898dfefa7c60684fc2b0d4c.jpg: 288x320 1 kidney_stone, 7.8ms\n",
      "image 82/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740171276284352500001-5536100503549537984_png_jpg.rf.6c752f372102c35841b912700635b52c.jpg: 288x320 1 kidney_stone, 14.6ms\n",
      "image 83/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740182336793977500001-5411618083031416674_png_jpg.rf.e5633e55c0ecfc3f3df68ae9cc6ac411.jpg: 288x320 1 kidney_stone, 8.4ms\n",
      "image 84/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740603851327033200001-4922091647392565521_png_jpg.rf.bc80c50937c24b91dfea47c556fb48ee.jpg: 288x320 1 kidney_stone, 10.5ms\n",
      "image 85/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740603851401037500001-5653962457778157128_png_jpg.rf.b445c412045a7ec8222fdc54adc5f966.jpg: 288x320 1 kidney_stone, 16.3ms\n",
      "image 86/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740776755054623500001-5096250249767122026_png_jpg.rf.a6d8a3a084e145ba0c32c21f289e90e0.jpg: 288x320 1 kidney_stone, 9.2ms\n",
      "image 87/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740776755089625500001-5715333660514809165_png_jpg.rf.cc64673ae8ce9ed7ba042d2717fa0056.jpg: 288x320 1 kidney_stone, 14.4ms\n",
      "image 88/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580145779300001-5738206214797884235_png_jpg.rf.813f84efb853afe1a7c011cfdbc5bfdb.jpg: 288x320 2 kidney_stones, 12.8ms\n",
      "image 89/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580178781200001-5086422129430942692_png_jpg.rf.c140dab363dde8a657b4e0c672251779.jpg: 288x320 2 kidney_stones, 20.7ms\n",
      "image 90/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580218783500001-5558521882885011993_png_jpg.rf.2fb14f6a674b0c7cb403f2b1e8da4215.jpg: 288x320 2 kidney_stones, 39.8ms\n",
      "image 91/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63740863580251785300001-5117110417075166265_png_jpg.rf.8d97967148ac132c7b84edf4a7a2cf99.jpg: 288x320 1 kidney_stone, 14.7ms\n",
      "image 92/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124799968194600001-5226103760366600348_png_jpg.rf.dd21b253d48ea5394c015dd3c4c7baa1.jpg: 288x320 2 kidney_stones, 14.5ms\n",
      "image 93/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800042198800001-5620738533970805933_png_jpg.rf.4fcc14fc70278a025316a0bd3ac8c041.jpg: 288x320 1 kidney_stone, 16.1ms\n",
      "image 94/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800130203900001-5588831013201724390_png_jpg.rf.a6a8bd9fc7caa4bea7dbe463acc3e107.jpg: 288x320 2 kidney_stones, 14.4ms\n",
      "image 95/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800310214100001-4720519192278742503_png_jpg.rf.bbe6f1a7a488baad44ab26628b67b2c0.jpg: 288x320 2 kidney_stones, 17.2ms\n",
      "image 96/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741124800443221800001-5082720743108815097_png_jpg.rf.2661995bf870c49d3af1255e0df65ed9.jpg: 288x320 1 kidney_stone, 16.8ms\n",
      "image 97/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741210469363203700001-5207129079094969383_png_jpg.rf.80f02c0e92710147b575da5b1c8955a8.jpg: 288x320 1 kidney_stone, 11.4ms\n",
      "image 98/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924210744700001-5683531657603489849_png_jpg.rf.aa3cbe8fe88c6f8a7ae446b2a75f3f92.jpg: 288x320 1 kidney_stone, 10.6ms\n",
      "image 99/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924248746800001-5006117639889310336_png_jpg.rf.4d8cfc579a4e01ffc2e34e26bb4622f6.jpg: 288x320 2 kidney_stones, 14.0ms\n",
      "image 100/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924341752200001-5737252104776306241_png_jpg.rf.c197a107f4dfd4e4687e24d668168a0a.jpg: 288x320 1 kidney_stone, 15.7ms\n",
      "image 101/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924448758300001-5675975946400058540_png_jpg.rf.c5fa641bd708da4cd5a8ace3ecff0fef.jpg: 288x320 2 kidney_stones, 7.5ms\n",
      "image 102/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741294924489760600001-5389065497535856101_png_jpg.rf.0a6c724d073923e3c678bcb59e79980c.jpg: 288x320 1 kidney_stone, 13.5ms\n",
      "image 103/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741467279526392800001-4770571118760501971_png_jpg.rf.68ee22f61fbbb636a8586b24471c2690.jpg: 288x320 2 kidney_stones, 8.4ms\n",
      "image 104/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741467279569395300001-4987275607072780944_png_jpg.rf.e69a5d34ddb4075908185b3a8244a1d5.jpg: 288x320 2 kidney_stones, 10.5ms\n",
      "image 105/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741736586529041200001-5705137549013784232_png_jpg.rf.5898be3563e8ee88ee98154d6be94a55.jpg: 288x320 1 kidney_stone, 17.7ms\n",
      "image 106/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741736586601045300001-5653145914170335853_png_jpg.rf.1ddd466cdd9d53b1d230a680848d709e.jpg: 288x320 1 kidney_stone, 9.8ms\n",
      "image 107/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741742547533991200001-4692411709729471462_png_jpg.rf.b367d9d12a074a9a2030e1a6761c702c.jpg: 288x320 1 kidney_stone, 12.6ms\n",
      "image 108/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741742547563992900001-4813696569989847626_png_jpg.rf.d120dd9eb2922de504cdac0a020eec69.jpg: 288x320 1 kidney_stone, 15.1ms\n",
      "image 109/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741807855851697400001-4668128765309155012_png_jpg.rf.d90c488d99c9f59fe506186cb73e51bb.jpg: 288x320 3 kidney_stones, 10.3ms\n",
      "image 110/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63741807855890699700001-4907588049082837513_png_jpg.rf.bdfab3beeb6f06e4a84bea1be29819fc.jpg: 288x320 1 kidney_stone, 24.3ms\n",
      "image 111/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742411918650702800001-4846811686601840839_png_jpg.rf.c7fdec8546601c5e51e70a059148f2bf.jpg: 288x320 1 kidney_stone, 10.2ms\n",
      "image 112/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414253972275600001-5472557700106786954_png_jpg.rf.2eaff0bf29d5ec6f8728d7ea0c51a4a1.jpg: 288x320 2 kidney_stones, 7.8ms\n",
      "image 113/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254071281200001-5199201186977930207_png_jpg.rf.3712dc035190e6f6f9770a51d306e040.jpg: 288x320 (no detections), 9.8ms\n",
      "image 114/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254117283900001-5038436008074711175_png_jpg.rf.727256debe0b69a6b199349acf584ab0.jpg: 288x320 2 kidney_stones, 7.6ms\n",
      "image 115/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742414254175287200001-5117478622886794000_png_jpg.rf.ebca7f6aa7bb26247ad62d333baebc68.jpg: 288x320 1 kidney_stone, 12.5ms\n",
      "image 116/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742500641013920000001-4736692753633727997_png_jpg.rf.25c7e0a9fe00ed38f512ddd6f63cf3cb.jpg: 288x320 1 kidney_stone, 9.7ms\n",
      "image 117/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742500641047921900001-5432446600076880623_png_jpg.rf.3980c6219cf1cfc92101f408bbd3a5aa.jpg: 288x320 1 kidney_stone, 12.1ms\n",
      "image 118/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742678653846928000001-5308440518832031451_png_jpg.rf.115cdf761943a8faaa63e13139c24f56.jpg: 288x320 1 kidney_stone, 10.8ms\n",
      "image 119/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456580448800001-4663254346399718819_png_jpg.rf.9c5d4e116bec0275104b14b3f7b5b10e.jpg: 288x320 1 kidney_stone, 7.8ms\n",
      "image 120/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456616450900001-5200753212886535539_png_jpg.rf.4c74939464255c6495fddb61d831df4f.jpg: 288x320 1 kidney_stone, 9.5ms\n",
      "image 121/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63742939456749458500001-4962227765358704856_png_jpg.rf.9e1bcdf85edc4c26b13e14e896cd7fae.jpg: 288x320 1 kidney_stone, 7.4ms\n",
      "image 122/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63743022346943480100001-5056079291509312712_png_jpg.rf.04a78eccdbc86bc603e24d4b9224a27d.jpg: 288x320 1 kidney_stone, 7.7ms\n",
      "image 123/123 C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\\1-3-46-670589-33-1-63743022347069487300001-5100284836990062688_png_jpg.rf.a63070c6a45f65acabf6e15dbb645a92.jpg: 288x320 1 kidney_stone, 9.2ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 3.2ms postprocess per image at shape (1, 3, 288, 320)\n",
      "âœ… Results saved to yolo_classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the best model\n",
    "model = YOLO(r'C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\model\\kidney-stone-yolo\\yolov8s-classifier2\\weights\\best.pt')\n",
    "\n",
    "# Inference source (folder with test images)\n",
    "source_folder = r\"C:\\Users\\Yaswanth Reddy\\KidneyStoneDetection\\dataset\\test\\images\"  # <-- change this to your test folder\n",
    "results = model.predict(source=source_folder, save=False)\n",
    "\n",
    "# Prepare output data\n",
    "output = []\n",
    "\n",
    "for result in results:\n",
    "    image_path = result.path\n",
    "    image_name = os.path.basename(image_path)\n",
    "\n",
    "    # Check if probs exist (only for classification models)\n",
    "    if result.probs:\n",
    "        probs = result.probs.data.tolist()\n",
    "        predicted_index = probs.index(max(probs))\n",
    "        predicted_class = model.names[predicted_index]\n",
    "        confidence = max(probs)\n",
    "    else:\n",
    "        predicted_class = \"Unknown\"\n",
    "        confidence = 0.0\n",
    "\n",
    "    output.append({\n",
    "        \"Image\": image_name,\n",
    "        \"Predicted Class\": predicted_class,\n",
    "        \"Confidence\": round(confidence, 4)\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(output)\n",
    "df.to_csv(\"yolo_classification_results.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Results saved to yolo_classification_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"yolo_classification_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-3-46-670589-33-1-63703718086120120200001-548...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-3-46-670589-33-1-63705534438365105500001-527...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-3-46-670589-33-1-63705540012666937300001-567...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-3-46-670589-33-1-63705542123217653900001-530...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-3-46-670589-33-1-63705542123253656000001-487...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image Predicted Class  \\\n",
       "0  1-3-46-670589-33-1-63703718086120120200001-548...         Unknown   \n",
       "1  1-3-46-670589-33-1-63705534438365105500001-527...         Unknown   \n",
       "2  1-3-46-670589-33-1-63705540012666937300001-567...         Unknown   \n",
       "3  1-3-46-670589-33-1-63705542123217653900001-530...         Unknown   \n",
       "4  1-3-46-670589-33-1-63705542123253656000001-487...         Unknown   \n",
       "\n",
       "   Confidence  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
